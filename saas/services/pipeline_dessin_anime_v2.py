#!/usr/bin/env python3
"""
ğŸ¬ Pipeline de GÃ©nÃ©ration de Dessin AnimÃ© IA
ImplÃ©mentation complÃ¨te selon les spÃ©cifications fonctionnelles
"""

import json
import os
import asyncio
import aiohttp
import subprocess
import requests  # Ajout pour Stability AI
import base64  # Pour dÃ©coder les vidÃ©os base64
from typing import List, Dict, Any
from pathlib import Path
import time
import openai
from openai import AsyncOpenAI
from PIL import Image  # Pour redimensionner les images

class DessinAnimePipeline:
    """Pipeline modulaire pour gÃ©nÃ©ration de dessins animÃ©s IA"""
    
    def __init__(self, openai_api_key: str, stability_api_key: str):
        self.openai_client = AsyncOpenAI(api_key=openai_api_key)
        self.stability_api_key = stability_api_key
        self.mode = "demo"  # Mode par dÃ©faut
        
        # Configuration
        self.cache_dir = Path("cache/animations")
        self.clips_dir = self.cache_dir / "clips"
        self.final_dir = self.cache_dir / "final"
        
        # CrÃ©er les rÃ©pertoires
        for dir_path in [self.cache_dir, self.clips_dir, self.final_dir]:
            dir_path.mkdir(parents=True, exist_ok=True)
    
    async def decouper_histoire_en_scenes(self, histoire: str, duree_totale: int) -> List[Dict[str, Any]]:
        """
        Ã‰tape 1: DÃ©couper l'histoire en 8-12 scÃ¨nes visuelles
        """
        print(f"ğŸ¬ Ã‰tape 1: DÃ©coupage de l'histoire en scÃ¨nes (durÃ©e cible: {duree_totale}s)")
        
        # Calculer le nombre de scÃ¨nes optimal
        nb_scenes = max(8, min(12, duree_totale // 20))  # 20s par scÃ¨ne en moyenne
        duree_par_scene = duree_totale // nb_scenes
        
        prompt = f"""Tu es un expert en narration visuelle pour dessins animÃ©s enfants.

HISTOIRE Ã€ DÃ‰COUPER:
{histoire}

CONTRAINTES:
- DÃ©couper en {nb_scenes} scÃ¨nes visuelles distinctes
- DurÃ©e cible par scÃ¨ne: {duree_par_scene} secondes
- Chaque scÃ¨ne doit Ãªtre visuellement marquante et adaptÃ©e aux enfants
- PrivilÃ©gier les actions et mouvements visibles
- Ã‰viter les dialogues longs, se concentrer sur l'action visuelle

STRUCTURE DE RÃ‰PONSE JSON EXACTE:
{{
    "total_scenes": {nb_scenes},
    "duree_totale_cible": {duree_totale},
    "scenes": [
        {{
            "id": 1,
            "description": "Description visuelle prÃ©cise de la scÃ¨ne",
            "duree_estimee": {duree_par_scene},
            "action_principale": "Action ou mouvement principal",
            "personnages": ["personnage1", "personnage2"],
            "decor": "Description du dÃ©cor/environnement"
        }}
    ]
}}"""

        try:
            response = await self.openai_client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.7,
                max_tokens=2000
            )
            
            content = response.choices[0].message.content.strip()
            
            # Nettoyer le JSON
            if content.startswith("```json"):
                content = content.replace("```json", "").replace("```", "").strip()
            
            scenes_data = json.loads(content)
            print(f"âœ… {scenes_data['total_scenes']} scÃ¨nes gÃ©nÃ©rÃ©es")
            
            return scenes_data['scenes']
            
        except Exception as e:
            print(f"âŒ Erreur dÃ©coupage: {e}")
            # Fallback simple
            return [
                {
                    "id": i+1,
                    "description": f"ScÃ¨ne {i+1} de l'histoire",
                    "duree_estimee": duree_par_scene,
                    "action_principale": "Action narrative",
                    "personnages": ["personnage principal"],
                    "decor": "Environnement de l'histoire"
                }
                for i in range(nb_scenes)
            ]
    
    async def definir_style_et_seeds(self, scenes: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        Ã‰tape 2: DÃ©finir style visuel homogÃ¨ne et seeds pour cohÃ©rence
        """
        print("ğŸ¨ Ã‰tape 2: DÃ©finition du style visuel et seeds")
        
        # Extraire personnages et lieux rÃ©currents
        tous_personnages = set()
        tous_lieux = set()
        
        for scene in scenes:
            tous_personnages.update(scene.get('personnages', []))
            tous_lieux.add(scene.get('decor', ''))
        
        prompt = f"""Tu es un directeur artistique pour dessins animÃ©s enfants.

SCÃˆNES Ã€ STYLISER:
{json.dumps(scenes, indent=2, ensure_ascii=False)}

OBJECTIF:
CrÃ©er un style visuel cohÃ©rent et des seeds pour garantir la consistance entre les clips.

STRUCTURE DE RÃ‰PONSE JSON EXACTE:
{{
    "style_global": "description complÃ¨te du style visuel (couleurs, ambiance, technique d'animation)",
    "palette_couleurs": ["#couleur1", "#couleur2", "#couleur3"],
    "ambiance": "magique/aventureuse/douce/etc",
    "seeds": {{
        "style_principal": 12345,
        "environnement_principal": 23456
    }},
    "qualite_tags": ["high quality", "detailed", "colorful", "child-friendly"],
    "style_prompt_base": "prompt de base Ã  injecter dans chaque gÃ©nÃ©ration"
}}"""

        try:
            response = await self.openai_client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.6,
                max_tokens=1500
            )
            
            content = response.choices[0].message.content.strip()
            if content.startswith("```json"):
                content = content.replace("```json", "").replace("```", "").strip()
            
            style_data = json.loads(content)
            print(f"âœ… Style dÃ©fini: {style_data['ambiance']}")
            
            return style_data
            
        except Exception as e:
            print(f"âŒ Erreur style: {e}")
            # Fallback
            return {
                "style_global": "Dessin animÃ© colorÃ© et lumineux adaptÃ© aux enfants",
                "palette_couleurs": ["#FFB6C1", "#87CEEB", "#98FB98"],
                "ambiance": "magique",
                "seeds": {"style_principal": 12345, "environnement_principal": 23456},
                "qualite_tags": ["high quality", "detailed", "colorful", "child-friendly"],
                "style_prompt_base": "beautiful animated style, child-friendly, colorful"
            }
    
    async def generer_prompts_videos(self, scenes: List[Dict[str, Any]], style: Dict[str, Any]) -> List[Dict[str, Any]]:
        """
        Ã‰tape 3: GÃ©nÃ©rer prompts text-to-video optimisÃ©s pour SD3-Turbo
        """
        print("ğŸ“ Ã‰tape 3: GÃ©nÃ©ration des prompts vidÃ©o")
        
        prompts = []
        
        for scene in scenes:
            prompt = f"""You are an expert in text-to-video prompts for Stability AI.

SCENE TO CONVERT:
{json.dumps(scene, indent=2, ensure_ascii=False)}

IMPOSED STYLE:
{json.dumps(style, indent=2, ensure_ascii=False)}

OBJECTIVE:
Create an optimized prompt for SD3-Turbo that generates a {scene['duree_estimee']}s video clip.

EXACT JSON RESPONSE STRUCTURE:
{{
    "scene_id": {scene['id']},
    "prompt_text": "complete prompt optimized for text-to-video IN ENGLISH ONLY",
    "prompt_text_english": "same prompt in English for Stability AI",
    "duration": {scene['duree_estimee']},
    "seed": {style['seeds']['style_principal']},
    "camera_movement": "camera movement description",
    "visual_elements": ["element1", "element2"],
    "style_tags": {json.dumps(style['qualite_tags'])}
}}

PROMPT RULES:
- WRITE EVERYTHING IN ENGLISH (Stability AI requirement)
- Maximum 500 characters
- Describe action, movement, atmosphere
- Include camera movement (zoom, pan, tracking)
- Visual style naturally integrated
- Optimized for text-to-video, not static image
- Child-friendly cartoon style
- Use words like: cartoon, animated, colorful, cute, friendly"""

            try:
                response = await self.openai_client.chat.completions.create(
                    model="gpt-4o-mini",
                    messages=[{"role": "user", "content": prompt}],
                    temperature=0.7,
                    max_tokens=800
                )
                
                content = response.choices[0].message.content.strip()
                if content.startswith("```json"):
                    content = content.replace("```json", "").replace("```", "").strip()
                
                prompt_data = json.loads(content)
                prompts.append(prompt_data)
                
            except Exception as e:
                print(f"âŒ Erreur prompt scÃ¨ne {scene['id']}: {e}")
                # Fallback
                prompts.append({
                    "scene_id": scene['id'],
                    "prompt_text": f"{style['style_prompt_base']}, {scene['description']}, {scene['action_principale']}",
                    "duration": scene['duree_estimee'],
                    "seed": style['seeds']['style_principal'],
                    "camera_movement": "smooth camera movement",
                    "visual_elements": scene.get('personnages', []),
                    "style_tags": style['qualite_tags']
                })
        
        print(f"âœ… {len(prompts)} prompts gÃ©nÃ©rÃ©s")
        return prompts
    
    async def generer_clips_video(self, prompts: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        Ã‰tape 4: GÃ©nÃ©rer les clips vidÃ©o via Stability AI
        """
        if self.mode == "production":
            print("ğŸ¥ Ã‰tape 4: GÃ©nÃ©ration des clips vidÃ©o avec Stability AI (MODE PRODUCTION)")
        else:
            print("ğŸ¥ Ã‰tape 4: GÃ©nÃ©ration des clips vidÃ©o (MODE DÃ‰MO)")
        
        clips = []
        
        for prompt_data in prompts:
            print(f"   GÃ©nÃ©ration clip scÃ¨ne {prompt_data['scene_id']}...")
            
            if self.mode == "production":
                try:
                    # Mode production : vraie gÃ©nÃ©ration Stability AI
                    print(f"      ğŸ¬ Tentative gÃ©nÃ©ration Stability AI...")
                    clip_result = await self._generer_clip_stability_ai(prompt_data)
                    
                    if clip_result:
                        clips.append(clip_result)
                        print(f"      âœ… Clip Stability AI gÃ©nÃ©rÃ© avec succÃ¨s")
                    else:
                        print(f"      âš ï¸ Clip Stability AI vide - fallback vers dÃ©mo")
                        clip_result = await self._generer_clip_demo(prompt_data)
                        clips.append(clip_result)
                    
                    # Pause entre les gÃ©nÃ©rations pour Ã©viter la rate limit
                    await asyncio.sleep(2)
                    
                except Exception as e:
                    print(f"      âŒ ERREUR Stability AI pour scÃ¨ne {prompt_data['scene_id']}: {e}")
                    print(f"      ğŸ“‹ Type d'erreur: {type(e).__name__}")
                    import traceback
                    print(f"      ğŸ“ DÃ©tails: {traceback.format_exc()}")
                    print("      ğŸ”„ Fallback vers gÃ©nÃ©ration de dÃ©mo...")
                    
                    # Fallback vers dÃ©mo en cas d'erreur
                    clip_result = await self._generer_clip_demo(prompt_data)
                    clips.append(clip_result)
            else:
                # Mode dÃ©mo : gÃ©nÃ©ration rapide avec images
                clip_result = await self._generer_clip_demo(prompt_data)
                clips.append(clip_result)
        
        print(f"âœ… {len(clips)} clips gÃ©nÃ©rÃ©s")
        return clips

    async def _generer_clip_stability_ai(self, prompt_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        GÃ©nÃ©ration de clip vidÃ©o rÃ©elle via Stability AI
        """
        scene_id = prompt_data['scene_id']
        
        # Pour SD3-Turbo, nous devons d'abord gÃ©nÃ©rer une image, puis la convertir en vidÃ©o
        # Ã‰tape 1: GÃ©nÃ©rer une image de base avec SD3
        image_result = await self._generer_image_sd3(prompt_data)
        
        if not image_result:
            raise Exception("Ã‰chec gÃ©nÃ©ration image de base")
        
        # Ã‰tape 2: Convertir l'image en vidÃ©o avec Stable Video Diffusion
        video_result = await self._image_to_video_stability(image_result, prompt_data)
        
        if not video_result:
            raise Exception("Ã‰chec conversion image vers vidÃ©o")
        
        return {
            "scene_number": scene_id,
            "scene_id": scene_id,
            "video_path": video_result['video_path'],
            "video_url": video_result['video_url'],
            "image_url": image_result['image_url'],  # Image de base
            "thumbnail_url": image_result['image_url'],
            "status": "success",
            "statut": "generated",
            "duration": prompt_data['duration'],
            "prompt": prompt_data['prompt_text'],
            "generation_method": "stability_ai",
            "type": "real_video",
            "metadata": {
                "scene_id": scene_id,
                "image_generation": image_result,
                "video_generation": video_result,
                "timestamp": time.time()
            }
        }

    async def _generer_image_sd3(self, prompt_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        GÃ©nÃ©rer une image de base avec SD3
        """
        print(f"      ğŸ–¼ï¸ GÃ©nÃ©ration image SD3 pour scÃ¨ne {prompt_data['scene_id']}")
        
        url = "https://api.stability.ai/v2beta/stable-image/generate/sd3"
        
        headers = {
            "Authorization": f"Bearer {self.stability_api_key}",
            "Accept": "image/*",
        }
        
        # Optimiser le prompt pour SD3 (utiliser la version anglaise)
        prompt_text = prompt_data.get('prompt_text_english', prompt_data.get('prompt_text', ''))
        optimized_prompt = f"{prompt_text}, single frame, high quality animation style, colorful, child-friendly"
        
        # SOLUTION: Utiliser requests pour Stability AI (fonctionne!)
        headers_req = {
            "Authorization": f"Bearer {self.stability_api_key}",
            "Accept": "image/*",
        }
        
        files = {
            "prompt": (None, optimized_prompt),
            "mode": (None, "text-to-image"),
            "model": (None, "sd3-medium"),
            "seed": (None, str(prompt_data.get('seed', 12345))),
            "output_format": (None, "png"),
            "width": (None, "1024"),
            "height": (None, "576")  # Format 16:9 compatible avec Stable Video
        }
        
        try:
            response = requests.post(url, headers=headers_req, files=files, timeout=60)
            
            print(f"        ğŸ“Š Status SD3: {response.status_code}")
            
            if response.status_code == 200:
                # Sauvegarder l'image temporaire
                image_data = response.content
                temp_image_path = self.clips_dir / f"scene_{prompt_data['scene_id']}_temp.png"
                
                with open(temp_image_path, 'wb') as f:
                    f.write(image_data)
                
                # Redimensionner pour Stable Video (1024x576)
                with Image.open(temp_image_path) as img:
                    # Redimensionner en gardant le ratio et en centrant
                    resized_img = img.resize((1024, 576), Image.Resampling.LANCZOS)
                    
                    # Sauvegarder l'image redimensionnÃ©e
                    image_filename = f"scene_{prompt_data['scene_id']}_base.png"
                    image_path = self.clips_dir / image_filename
                    resized_img.save(image_path, "PNG")
                
                # Supprimer l'image temporaire
                temp_image_path.unlink(missing_ok=True)
                
                print(f"        âœ… Image gÃ©nÃ©rÃ©e et redimensionnÃ©e: {image_filename} (1024x576)")
                
                return {
                    "image_path": str(image_path),
                    "image_url": f"/cache/animations/clips/{image_filename}",
                    "generation_id": f"sd3_{prompt_data['scene_id']}_{int(time.time())}"
                }
            else:
                error_text = response.text
                print(f"        âŒ Erreur SD3: {response.status_code} - {error_text}")
                return None
                
        except Exception as e:
            print(f"        ğŸ’¥ Exception requests: {e}")
            return None

    async def _image_to_video_stability(self, image_result: Dict[str, Any], prompt_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        Convertir l'image en vidÃ©o avec Stable Video Diffusion
        """
        print(f"      ğŸ¬ Conversion imageâ†’vidÃ©o pour scÃ¨ne {prompt_data['scene_id']}")
        
        url = "https://api.stability.ai/v2beta/image-to-video"
        
        headers = {
            "Authorization": f"Bearer {self.stability_api_key}",
        }
        
        # PrÃ©parer l'image pour upload
        image_path = image_result['image_path']
        
        # SOLUTION: Utiliser requests pour la conversion imageâ†’vidÃ©o aussi
        try:
            with open(image_path, 'rb') as image_file:
                files = {
                    'image': ('input.png', image_file, 'image/png'),
                    'seed': (None, str(prompt_data.get('seed', 12345))),
                    'cfg_scale': (None, '2.5'),
                    'motion_bucket_id': (None, '127'),
                }
                
                response = requests.post(url, headers=headers, files=files, timeout=60)
                
                print(f"        ğŸ“Š Status conversion: {response.status_code}")
                
                if response.status_code == 200:
                    content_type = response.headers.get('content-type', '')
                    response_text = response.text
                    
                    print(f"        ğŸ“Š Content-Type: {content_type}")
                    print(f"        ğŸ“Š Response length: {len(response_text)}")
                    print(f"        ğŸ“Š Response starts with: {response_text[:50]}...")
                    
                    # VÃ©rifier si c'est du JSON
                    try:
                        result = response.json()
                        generation_id = result.get('id')
                        
                        if generation_id:
                            print(f"        ğŸ¬ GÃ©nÃ©ration ID: {generation_id}")
                            # Attendre et rÃ©cupÃ©rer le rÃ©sultat
                            video_result = await self._wait_for_video_result(generation_id)
                            return video_result
                        else:
                            print(f"        âŒ Pas d'ID de gÃ©nÃ©ration reÃ§u")
                            return None
                    except:
                        # Ce n'est pas du JSON valide
                        pass
                    
                    # VÃ©rifier si c'est une rÃ©ponse vidÃ©o en base64 ou binaire
                    if 'video/' in content_type or len(response.content) > 10000:
                        # RÃ©ponse directe avec vidÃ©o binaire
                        print(f"        âœ… VidÃ©o binaire reÃ§ue directement ({len(response.content)} bytes)")
                        
                        scene_id = prompt_data['scene_id']
                        video_filename = f"scene_{scene_id}_{int(time.time())}.mp4"
                        video_path = self.clips_dir / video_filename
                        
                        with open(video_path, 'wb') as f:
                            f.write(response.content)
                        
                        print(f"        ğŸ’¾ VidÃ©o sauvegardÃ©e: {video_filename}")
                        
                        return {
                            "video_path": str(video_path),
                            "video_url": f"/cache/animations/clips/{video_filename}",
                            "generation_id": f"direct_{scene_id}"
                        }
                    elif len(response_text) > 1000 and (response_text.startswith('UklGR') or response_text.startswith('//')):
                        # RÃ©ponse directe avec vidÃ©o en base64
                        print(f"        âœ… VidÃ©o base64 reÃ§ue directement ({len(response_text)} caractÃ¨res)")
                        
                        try:
                            # DÃ©coder le base64
                            video_data = base64.b64decode(response_text)
                            
                            scene_id = prompt_data['scene_id']
                            video_filename = f"scene_{scene_id}_{int(time.time())}.mp4"
                            video_path = self.clips_dir / video_filename
                            
                            with open(video_path, 'wb') as f:
                                f.write(video_data)
                            
                            print(f"        ğŸ’¾ VidÃ©o dÃ©codÃ©e et sauvegardÃ©e: {video_filename}")
                            
                            return {
                                "video_path": str(video_path),
                                "video_url": f"/cache/animations/clips/{video_filename}",
                                "generation_id": f"direct_{scene_id}"
                            }
                        except Exception as e:
                            print(f"        âŒ Erreur dÃ©codage base64: {e}")
                            return None
                    else:
                        print(f"        â“ Type de contenu inattendu: {content_type}")
                        print(f"        â“ Longueur: {len(response_text)}")
                        return None
                else:
                    error_text = response.text
                    print(f"        âŒ Erreur image-to-video: {response.status_code} - {error_text}")
                    return None
                    
        except Exception as e:
            print(f"        ğŸ’¥ Exception conversion: {e}")
            return None

    async def _wait_for_video_result(self, generation_id: str) -> Dict[str, Any]:
        """
        Attendre et rÃ©cupÃ©rer le rÃ©sultat de gÃ©nÃ©ration vidÃ©o
        """
        print(f"      â³ Attente gÃ©nÃ©ration vidÃ©o {generation_id}")
        
        url = f"https://api.stability.ai/v2beta/image-to-video/result/{generation_id}"
        headers = {
            "Authorization": f"Bearer {self.stability_api_key}",
            "Accept": "application/json"
        }
        
        max_attempts = 30  # Maximum 5 minutes d'attente
        attempt = 0
        
        async with aiohttp.ClientSession() as session:
            while attempt < max_attempts:
                await asyncio.sleep(10)  # Attendre 10 secondes entre chaque vÃ©rification
                attempt += 1
                
                async with session.get(url, headers=headers) as response:
                    print(f"      ğŸ“Š Status check: {response.status}")
                    
                    if response.status == 200:
                        content_type = response.headers.get('content-type', '')
                        print(f"      ğŸ“Š Content-Type: {content_type}")
                        
                        if 'application/json' in content_type:
                            result = await response.json()
                            print(f"      ğŸ“Š JSON keys: {list(result.keys())}")
                            
                            # VÃ©rifier si c'est une URL de tÃ©lÃ©chargement
                            video_url = result.get('video')
                            if video_url:
                                print(f"      ğŸ”— DonnÃ©es vidÃ©o trouvÃ©es: {video_url[:50]}...")
                                
                                # VÃ©rifier si c'est une URL ou du base64
                                if video_url.startswith('http'):
                                    # C'est une URL, tÃ©lÃ©charger
                                    video_filename = f"scene_{generation_id}.mp4"
                                    video_path = self.clips_dir / video_filename
                                    
                                    async with session.get(video_url) as video_response:
                                        if video_response.status == 200:
                                            video_data = await video_response.read()
                                            with open(video_path, 'wb') as f:
                                                f.write(video_data)
                                            
                                            print(f"      âœ… VidÃ©o tÃ©lÃ©chargÃ©e: {video_filename}")
                                            
                                            return {
                                                "video_path": str(video_path),
                                                "video_url": f"/cache/animations/clips/{video_filename}",
                                                "generation_id": generation_id
                                            }
                                else:
                                    # C'est du base64, dÃ©coder directement
                                    try:
                                        video_data = base64.b64decode(video_url)
                                        
                                        video_filename = f"scene_{generation_id}.mp4"
                                        video_path = self.clips_dir / video_filename
                                        
                                        with open(video_path, 'wb') as f:
                                            f.write(video_data)
                                        
                                        print(f"      âœ… VidÃ©o base64 dÃ©codÃ©e: {video_filename}")
                                        
                                        return {
                                            "video_path": str(video_path),
                                            "video_url": f"/cache/animations/clips/{video_filename}",
                                            "generation_id": generation_id
                                        }
                                    except Exception as e:
                                        print(f"      âŒ Erreur dÃ©codage base64: {e}")
                                        return None
                            
                            # VÃ©rifier si la vidÃ©o est directement en base64 dans la rÃ©ponse
                            elif 'video' in result or any(k for k in result.keys() if 'video' in k.lower()):
                                print(f"      ğŸ“¹ VidÃ©o trouvÃ©e dans JSON")
                                # Chercher le champ contenant la vidÃ©o
                                video_content = None
                                for key, value in result.items():
                                    if isinstance(value, str) and len(value) > 1000:
                                        video_content = value
                                        break
                                
                                if video_content:
                                    try:
                                        # Essayer de dÃ©coder le base64
                                        video_data = base64.b64decode(video_content)
                                        
                                        video_filename = f"scene_{generation_id}.mp4"
                                        video_path = self.clips_dir / video_filename
                                        
                                        with open(video_path, 'wb') as f:
                                            f.write(video_data)
                                        
                                        print(f"      âœ… VidÃ©o base64 dÃ©codÃ©e: {video_filename}")
                                        
                                        return {
                                            "video_path": str(video_path),
                                            "video_url": f"/cache/animations/clips/{video_filename}",
                                            "generation_id": generation_id
                                        }
                                    except Exception as e:
                                        print(f"      âŒ Erreur dÃ©codage: {e}")
                            
                            # VÃ©rifier le statut
                            status = result.get('status', '')
                            if status == 'in-progress':
                                print(f"      â³ GÃ©nÃ©ration en cours... (tentative {attempt}/{max_attempts})")
                                continue
                            elif status == 'complete':
                                print(f"      â“ GÃ©nÃ©ration complÃ¨te mais pas de vidÃ©o trouvÃ©e")
                                print(f"      ğŸ“‹ RÃ©ponse: {result}")
                                return None
                            else:
                                print(f"      â“ Statut inconnu: {status}")
                                print(f"      ğŸ“‹ RÃ©ponse: {result}")
                        else:
                            # RÃ©ponse non-JSON, peut-Ãªtre vidÃ©o directe
                            video_data = await response.read()
                            if len(video_data) > 1000:
                                video_filename = f"scene_{generation_id}.mp4"
                                video_path = self.clips_dir / video_filename
                                
                                with open(video_path, 'wb') as f:
                                    f.write(video_data)
                                
                                print(f"      âœ… VidÃ©o directe tÃ©lÃ©chargÃ©e: {video_filename}")
                                
                                return {
                                    "video_path": str(video_path),
                                    "video_url": f"/cache/animations/clips/{video_filename}",
                                    "generation_id": generation_id
                                }
                    
                    elif response.status == 202:
                        # Toujours en cours de gÃ©nÃ©ration
                        print(f"      â³ GÃ©nÃ©ration en cours... (tentative {attempt}/{max_attempts})")
                        continue
                    
                    else:
                        error_text = await response.text()
                        print(f"      âŒ Erreur vÃ©rification: {response.status} - {error_text}")
                        return None
        
        print(f"      â° Timeout: gÃ©nÃ©ration trop longue")
        return None
    
    async def _generer_clip_demo(self, prompt_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        GÃ©nÃ©ration de clip de dÃ©monstration (remplace SD3-Turbo temporairement)
        """
        scene_id = prompt_data['scene_id']
        
        # CrÃ©er un fichier JSON avec les mÃ©tadonnÃ©es du clip
        clip_metadata = {
            "scene_id": scene_id,
            "prompt": prompt_data['prompt_text'],
            "duration": prompt_data['duration'],
            "seed": prompt_data.get('seed', 12345),
            "status": "demo_generated",
            "timestamp": time.time()
        }
        
        # Sauvegarder les mÃ©tadonnÃ©es
        metadata_path = self.clips_dir / f"scene_{scene_id}_metadata.json"
        with open(metadata_path, 'w', encoding='utf-8') as f:
            json.dump(clip_metadata, f, ensure_ascii=False, indent=2)
        
        # Utiliser l'image SVG de dÃ©mo existante
        demo_image_path = f"/cache/animations/demo_images/scene_{scene_id}_demo.svg"
        
        return {
            "scene_number": scene_id,
            "scene_id": scene_id,
            "video_path": str(metadata_path),
            "video_url": demo_image_path,  # Pour la compatibilitÃ© 
            "image_url": demo_image_path,  # URL de l'image pour affichage immÃ©diat
            "demo_image_url": demo_image_path,
            "status": "success",
            "statut": "demo_ok",
            "duration": prompt_data['duration'],
            "prompt": prompt_data['prompt_text'],
            "metadata": clip_metadata,
            "type": "local_image"
        }
    
    async def assembler_video_finale(self, clips: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        Ã‰tape 5: Assembler les clips en vidÃ©o finale MP4
        """
        print("ğŸ¬ Ã‰tape 5: Assemblage vidÃ©o finale MP4")
        
        # SÃ©parer les vrais clips vidÃ©o des dÃ©mos
        vrais_clips = [c for c in clips if c.get('type') == 'real_video']
        clips_demo = [c for c in clips if c.get('type') != 'real_video']
        
        if vrais_clips:
            # Assembler les vraies vidÃ©os avec FFmpeg
            video_result = await self._assembler_videos_ffmpeg(clips)
        else:
            # Mode dÃ©mo : crÃ©er une playlist
            video_result = await self._creer_playlist_demo(clips)
        
        duree_totale = sum(clip.get('duration', 20) for clip in clips)
        
        result = {
            "video_finale_path": video_result['path'],
            "video_url": video_result['url'],
            "duree_totale": duree_totale,
            "clips_count": len(clips),
            "format": video_result['format'],
            "has_real_videos": len(vrais_clips) > 0,
            "demo_clips": len(clips_demo)
        }
        
        print(f"âœ… VidÃ©o finale assemblÃ©e: {duree_totale}s ({result['format']})")
        return result

    async def _assembler_videos_ffmpeg(self, clips: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        Assembler les clips vidÃ©o en MP4 final avec FFmpeg
        """
        print("      ğŸ”§ Assemblage FFmpeg...")
        
        import subprocess
        
        # CrÃ©er une liste des fichiers vidÃ©o
        video_files = []
        concat_file = self.final_dir / f"concat_{int(time.time())}.txt"
        
        with open(concat_file, 'w', encoding='utf-8') as f:
            for clip in clips:
                if clip.get('type') == 'real_video' and 'video_path' in clip:
                    video_path = clip['video_path']
                    if os.path.exists(video_path):
                        f.write(f"file '{os.path.abspath(video_path)}'\n")
                        video_files.append(video_path)
        
        if not video_files:
            raise Exception("Aucun fichier vidÃ©o valide Ã  assembler")
        
        # Nom du fichier final
        final_video_path = self.final_dir / f"dessin_anime_{int(time.time())}.mp4"
        
        # Commande FFmpeg pour concatener avec transitions douces
        ffmpeg_cmd = [
            'ffmpeg', '-y',  # -y pour overwrite
            '-f', 'concat',
            '-safe', '0',
            '-i', str(concat_file),
            '-c:v', 'libx264',  # Codec vidÃ©o
            '-preset', 'medium',  # QualitÃ©/vitesse
            '-crf', '23',  # QualitÃ© (lower = better)
            '-c:a', 'aac',  # Codec audio si prÃ©sent
            '-movflags', '+faststart',  # Optimisation web
            str(final_video_path)
        ]
        
        try:
            # ExÃ©cuter FFmpeg
            result = subprocess.run(ffmpeg_cmd, 
                                  capture_output=True, 
                                  text=True, 
                                  timeout=300)  # 5 minutes max
            
            if result.returncode == 0:
                print(f"      âœ… VidÃ©o assemblÃ©e: {final_video_path.name}")
                
                # Nettoyer le fichier concat temporaire
                concat_file.unlink(missing_ok=True)
                
                return {
                    "path": str(final_video_path),
                    "url": f"/cache/animations/final/{final_video_path.name}",
                    "format": "mp4"
                }
            else:
                print(f"      âŒ Erreur FFmpeg: {result.stderr}")
                raise Exception(f"FFmpeg failed: {result.stderr}")
                
        except subprocess.TimeoutExpired:
            print("      â° Timeout FFmpeg")
            raise Exception("Assemblage vidÃ©o trop long")
        except FileNotFoundError:
            print("      âŒ FFmpeg non trouvÃ©")
            # Fallback vers playlist
            return await self._creer_playlist_demo(clips)

    async def _creer_playlist_demo(self, clips: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        CrÃ©er une playlist de dÃ©monstration
        """
        print("      ğŸ“‹ CrÃ©ation playlist dÃ©mo...")
        
        playlist_data = {
            "clips": clips,
            "format": "demo_playlist",
            "timestamp": time.time(),
            "note": "Mode dÃ©monstration - utilisez des vraies vidÃ©os pour un MP4 final"
        }
        
        playlist_path = self.final_dir / f"playlist_{int(time.time())}.m3u8"
        with open(playlist_path, 'w', encoding='utf-8') as f:
            json.dump(playlist_data, f, ensure_ascii=False, indent=2)
        
        return {
            "path": str(playlist_path),
            "url": f"/cache/animations/final/{playlist_path.name}",
            "format": "playlist"
        }
        
        return {
            "video_finale_path": str(playlist_path),
            "video_url": f"/cache/animations/final/{playlist_path.name}",
            "duree_totale": duree_totale,
            "clips_count": len(clips),
            "format": "demo_playlist"
        }
    
    async def generer_dessin_anime_complet(self, histoire: str, duree_totale: int = 60) -> Dict[str, Any]:
        """
        Pipeline complet: histoire â†’ dessin animÃ©
        """
        print(f"\nğŸš€ DÃ‰BUT GÃ‰NÃ‰RATION DESSIN ANIMÃ‰")
        print(f"ğŸ“– Histoire: {histoire[:100]}...")
        print(f"â±ï¸ DurÃ©e cible: {duree_totale}s")
        
        start_time = time.time()
        
        try:
            # Ã‰tape 1: DÃ©coupage en scÃ¨nes
            scenes = await self.decouper_histoire_en_scenes(histoire, duree_totale)
            
            # Ã‰tape 2: Style et seeds
            style = await self.definir_style_et_seeds(scenes)
            
            # Ã‰tape 3: Prompts vidÃ©o
            prompts = await self.generer_prompts_videos(scenes, style)
            
            # Ã‰tape 4: GÃ©nÃ©ration clips
            clips = await self.generer_clips_video(prompts)
            
            # Ã‰tape 5: Assemblage final
            video_finale = await self.assembler_video_finale(clips)
            
            generation_time = time.time() - start_time
            
            # PrÃ©parer le rÃ©sultat dans le format attendu par le frontend
            result = {
                "status": "success",
                "message": "âœ… Animation gÃ©nÃ©rÃ©e avec succÃ¨s",
                "timeline": {
                    "total_duration": duree_totale,
                    "scenes_count": len(scenes),
                    "clips_count": len(clips)
                },
                "clips": clips,  # Les clips contiennent dÃ©jÃ  les image_url
                "video_finale": video_finale,
                "generation_time": generation_time,
                "pipeline_version": "v2.0_specs",
                
                # MÃ©tadonnÃ©es additionnelles pour compatibilitÃ©
                "scenes": scenes,
                "style": style,
                "histoire": histoire,
                "duree_totale": duree_totale
            }
            
            print(f"\nğŸ‰ GÃ‰NÃ‰RATION TERMINÃ‰E en {generation_time:.1f}s")
            return result
            
        except Exception as e:
            print(f"\nğŸ’¥ ERREUR PIPELINE: {e}")
            raise


# Fonction utilitaire pour l'intÃ©gration
async def creer_dessin_anime(histoire: str, duree: int, openai_key: str, stability_key: str, mode: str = "demo") -> Dict[str, Any]:
    """
    Fonction d'entrÃ©e principale pour l'API
    
    Args:
        histoire: Texte de l'histoire
        duree: DurÃ©e cible en secondes
        openai_key: ClÃ© API OpenAI
        stability_key: ClÃ© API Stability AI
        mode: "demo" pour mode test avec images, "production" pour vraies vidÃ©os
    """
    pipeline = DessinAnimePipeline(openai_key, stability_key)
    pipeline.mode = mode  # DÃ©finir le mode
    return await pipeline.generer_dessin_anime_complet(histoire, duree)


if __name__ == "__main__":
    # Test du pipeline
    import os
    from dotenv import load_dotenv
    
    load_dotenv()
    
    async def test_pipeline():
        openai_key = os.getenv("OPENAI_API_KEY")
        stability_key = os.getenv("STABILITY_API_KEY")
        
        if not openai_key or not stability_key:
            print("âŒ ClÃ©s API manquantes")
            return
        
        histoire = "Une petite licorne dÃ©couvre un jardin magique plein de fleurs qui chantent et de papillons colorÃ©s qui dansent au rythme de la musique du vent."
        
        result = await creer_dessin_anime(histoire, 90, openai_key, stability_key)
        
        print("\nğŸ“Š RÃ‰SULTAT:")
        print(f"âœ… Status: {result['status']}")
        print(f"ğŸ¬ ScÃ¨nes: {len(result['scenes'])}")
        print(f"ğŸ¥ Clips: {len(result['clips'])}")
        print(f"â±ï¸ DurÃ©e: {result['duree_totale']}s")
        print(f"ğŸ• Temps: {result['generation_time']:.1f}s")
    
    asyncio.run(test_pipeline())
