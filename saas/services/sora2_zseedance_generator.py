"""
Service de g√©n√©ration d'animations avec Runway ML Veo 3.1 Fast bas√© exactement sur le workflow zseedance.json
Impl√©mentation fid√®le au workflow n8n avec Veo 3.1 Fast pour la g√©n√©ration vid√©o
"""

import asyncio
import aiohttp
import json
import logging
import os
import uuid
from typing import List, Dict, Any, Optional
from datetime import datetime
import time

logger = logging.getLogger(__name__)


class Sora2ZseedanceGenerator:
    """
    G√©n√©rateur d'animations utilisant Runway ML Veo 3.1 Fast en suivant exactement le workflow zseedance.json
    Workflow optimis√© : Ideas ‚Üí Prompts ‚Üí Clips Veo 3.1 Fast (avec audio int√©gr√©) ‚Üí Sequence
    Note: Veo 3.1 Fast g√©n√®re automatiquement l'audio, pas besoin d'ajout s√©par√©
    """

    def __init__(self):
        # Configuration bas√©e sur les variables d'environnement existantes
        self.openai_api_key = os.getenv("OPENAI_API_KEY")
        self.text_model = os.getenv("TEXT_MODEL", "gpt-4o-mini")

        # V√©rification d√©taill√©e de la cl√© Runway
        runway_key = os.getenv("RUNWAY_API_KEY")
        logger.info(f"üîë Initialisation Runway ML Veo 3.1 Fast - RUNWAY_API_KEY: {'pr√©sente' if runway_key else 'ABSENTE'}")
        if runway_key:
            logger.info(f"üîë Format cl√©: {'‚úÖ OK (key_)' if runway_key.startswith('key_') else '‚ùå ERREUR format'}")
            logger.info(f"üîë Longueur: {len(runway_key)} caract√®res")

        # Configuration Runway ML Veo 3.1 Fast - text-to-video via /v1/text_to_video
        self.sora_platforms = {
            "openai": {
                "name": "OpenAI (Non disponible)",
                "base_url": "https://api.openai.com/v1",
                "api_key": self.openai_api_key,
                "model": "veo3.1_fast",  # Mod√®le Veo 3.1 Fast
                "available": False,  # D√©sactiv√© car pas disponible publiquement
                "priority": 99  # Priorit√© tr√®s basse
            },
            "runway": {
                "name": "Runway ML (Veo 3.1 Fast)",
                "base_url": "https://api.dev.runwayml.com",
                "api_key": runway_key,
                "model": "veo3.1_fast",  # Veo 3.1 Fast - text-to-video natif
                "available": bool(runway_key and runway_key.startswith('key_')),
                "priority": 1  # Priorit√© la plus haute maintenant
            },
            "pika": {
                "name": "Pika Labs (Alternative)",
                "base_url": "https://api.pika.art/v1",
                "api_key": os.getenv("PIKA_API_KEY"),
                "model": "pika-1.0",  # Mod√®le r√©el Pika
                "available": bool(os.getenv("PIKA_API_KEY")),
                "priority": 3
            }
        }

        # S√©lectionner la plateforme disponible avec la priorit√© la plus haute
        self.selected_platform = self._select_best_platform()

        # Configuration Veo 3.1 Fast optimis√©e pour enfants (identique √† zseedance)
        self.sora2_config = {
            "aspect_ratio": "9:16",  # Format vertical comme zseedance
            "duration_per_clip": 10,  # 10 secondes par clip comme zseedance
            "resolution": "480p",     # R√©solution comme zseedance
            "style": "2D cartoon animation, Disney Pixar style, child-friendly, vibrant colors, smooth fluid animation, expressive characters",
            "negative_prompt": "blurry, low quality, distorted, violent, scary, static, motionless, dark, horror"
        }

        logger.info(f"üé¨ Sora2ZseedanceGenerator initialis√© avec plateforme: {self.selected_platform}")
        logger.info(f"üîß Plateformes disponibles: {[name for name, config in self.sora_platforms.items() if config['available']]}")
        logger.info(f"üîë RUNWAY_API_KEY d√©tect√©e: {bool(os.getenv('RUNWAY_API_KEY'))}")
        if os.getenv('RUNWAY_API_KEY'):
            key = os.getenv('RUNWAY_API_KEY')
            logger.info(f"üîë Format cl√© Runway: {'‚úÖ OK' if key.startswith('key_') else '‚ùå ERREUR'}")
            logger.info(f"üîë Longueur cl√© Runway: {len(key)} caract√®res")
        logger.info(f"üîë FAL_API_KEY d√©tect√©e: {bool(os.getenv('FAL_API_KEY'))}")
        if os.getenv('FAL_API_KEY'):
            fal_key = os.getenv('FAL_API_KEY')
            logger.info(f"üîë Longueur cl√© FAL: {len(fal_key)} caract√®res")

    def _select_best_platform(self) -> str:
        """S√©lectionne la plateforme Veo 3.1 Fast disponible avec la priorit√© la plus haute"""
        available_platforms = [
            (name, config) for name, config in self.sora_platforms.items()
            if config["available"]
        ]

        if not available_platforms:
            logger.error("‚ùå Aucune plateforme Veo 3.1 Fast disponible - v√©rifiez les cl√©s API")
            raise Exception("Aucune plateforme Veo 3.1 Fast disponible - configurez RUNWAY_API_KEY")

        # Trier par priorit√©
        available_platforms.sort(key=lambda x: x[1]["priority"])
        best_platform = available_platforms[0][0]

        logger.info(f"‚úÖ Plateforme Veo 3.1 Fast s√©lectionn√©e: {best_platform}")
        return best_platform

    async def generate_ideas_agent_adapted(self, theme: str = "space") -> Dict[str, Any]:
        """
        Ideas AI Agent - G√©n√®re une id√©e cr√©ative adapt√©e au th√®me choisi par l'utilisateur
        Inspir√© de zseedance.json mais adapt√© aux th√®mes enfants
        """
        try:
            # Adaptation des th√®mes pour les enfants
            theme_adaptations = {
                "space": {
                    "subject": "space adventure with friendly aliens",
                    "environment": "cosmic setting with planets and stars",
                    "sound": "cosmic hums, gentle space winds, magical chimes",
                    "style": "child-friendly space exploration"
                },
                "ocean": {
                    "subject": "magical underwater adventure",
                    "environment": "beautiful ocean with coral reefs and sea creatures",
                    "sound": "gentle ocean waves, friendly sea creature calls, magical bubbles",
                    "style": "whimsical underwater exploration"
                },
                "forest": {
                    "subject": "enchanted forest adventure with magical creatures",
                    "environment": "mystical forest with glowing trees and magical creatures",
                    "sound": "gentle forest winds, magical creature whispers, enchanted chimes",
                    "style": "magical forest exploration for children"
                },
                "adventure": {
                    "subject": "exciting adventure with heroes and discoveries",
                    "environment": "magical world full of wonders and discoveries",
                    "sound": "adventurous music, heroic sounds, discovery chimes",
                    "style": "epic adventure suitable for children"
                },
                "fantasy": {
                    "subject": "magical fantasy world with wizards and dragons",
                    "environment": "enchanted kingdom with castles and magical creatures",
                    "sound": "magical spells, dragon roars (gentle), enchanted music",
                    "style": "child-friendly fantasy adventure"
                },
                "animals": {
                    "subject": "cute animals having fun adventures together",
                    "environment": "beautiful nature setting with friendly animals",
                    "sound": "happy animal sounds, playful music, joyful chimes",
                    "style": "cute animal adventure for children"
                }
            }

            # R√©cup√©rer l'adaptation du th√®me ou utiliser une valeur par d√©faut
            theme_config = theme_adaptations.get(theme.lower(), theme_adaptations["space"])

            # Prompt syst√®me strict pour forcer du JSON valide
            system_prompt = f"""You are a JSON generator for children's animation story ideas.

Create a magical animated story concept for: {theme_config['subject']}

REQUIREMENTS:
- Suitable for children 4-10 years old
- Friendly, positive characters only
- No scary elements, violence, or danger
- Focus on wonder, discovery, friendship, joy
- Colorful, magical animation style
- 3-5 friendly characters or creatures
- Complete story with beginning, middle, happy ending

OUTPUT: Return ONLY valid JSON with this exact structure:
{{
  "Caption": "üé¨ [Short title with emoji] #adventure #magic #friendship",
  "Idea": "[2-3 sentence complete story description]",
  "Environment": "[Magical {theme_config['style']} setting]",
  "Sound": "{theme_config['sound']}, happy children's music, joyful sounds",
  "Status": "for children"
}}"""

            # G√©n√©rer l'id√©e avec GPT-4o-mini
            try:
                from config import OPENAI_API_KEY, TEXT_MODEL
                if not OPENAI_API_KEY:
                    raise ValueError("OPENAI_API_KEY manquante")

                import openai
                client = openai.AsyncOpenAI(api_key=OPENAI_API_KEY)

                response = await client.chat.completions.create(
                    model=TEXT_MODEL,
                    messages=[
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": f"Create a magical animated story idea for children about {theme_config['subject']}."}
                    ],
                    response_format={"type": "json_object"},
                    max_tokens=600,
                    temperature=0.8
                )

                # Analyser la r√©ponse pour extraire le JSON
                content = response.choices[0].message.content.strip()
                logger.info(f"ü§ñ Id√©e g√©n√©r√©e: {content[:100]}...")

                # Essayer de parser le JSON
                try:
                    idea_data = json.loads(content)
                    return idea_data
                except json.JSONDecodeError:
                    logger.error(f"Erreur parsing JSON OpenAI: r√©ponse invalide")
                    raise Exception(f"OpenAI API a retourn√© un JSON invalide pour le th√®me '{theme}'")

            except Exception as api_error:
                logger.error(f"Erreur API OpenAI: {api_error}")
                raise Exception(f"√âchec g√©n√©ration id√©e pour th√®me '{theme}': {api_error}")

        except Exception as e:
            logger.error(f"Erreur g√©n√©ration id√©e adapt√©e: {e}")
            raise Exception(f"√âchec g√©n√©ration id√©e pour th√®me '{theme}': {e}")

    async def generate_prompts_agent_adapted(self, idea_data: Dict[str, Any], num_scenes: int = 3) -> Dict[str, Any]:
        """
        Prompts AI Agent - Cr√©e un nombre variable de sc√®nes d√©taill√©es pour l'animation
        Adapt√© pour les enfants et g√©n√®re des sc√®nes coh√©rentes formant une histoire compl√®te
        """
        try:
            # Cr√©er la liste des sc√®nes attendues
            scenes_keys = [f"Scene {i+1}" for i in range(num_scenes)]

            # Prompt syst√®me strict pour forcer du JSON valide
            system_prompt = f"""You are a JSON generator for children's animation scenes.

STORY: {idea_data['Idea']}
ENVIRONMENT: {idea_data['Environment']}
SOUND: {idea_data['Sound']}

Create {num_scenes} detailed scene descriptions for a children's animated story.
Each scene is exactly 10 seconds long and they form a complete story arc.

REQUIREMENTS:
- Magical, colorful, child-friendly content only
- Positive emotions, friendship, discovery, joy
- Disney/Pixar style 2D animation
- Vibrant colors, magical effects, expressive characters
- No scary elements or negative emotions

OUTPUT: Return ONLY valid JSON with this exact structure:
{{
  "Idea": "{idea_data['Idea']}",
  "Environment": "{idea_data['Environment']}",
  "Sound": "{idea_data['Sound']}",
  {', '.join([f'"{key}": "Detailed description for {key.lower()}"' for key in scenes_keys])}
}}"""

            # G√©n√©rer les sc√®nes avec GPT-4o-mini
            try:
                from config import OPENAI_API_KEY, TEXT_MODEL
                if not OPENAI_API_KEY:
                    raise ValueError("OPENAI_API_KEY manquante")

                import openai
                client = openai.AsyncOpenAI(api_key=OPENAI_API_KEY)

                response = await client.chat.completions.create(
                    model=TEXT_MODEL,
                    messages=[
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": f"Generate {num_scenes} connected animation scenes for this children's story. Each scene must be detailed enough for a 10-second animation clip."}
                    ],
                    response_format={"type": "json_object"},
                    max_tokens=1000,
                    temperature=0.7
                )

                # Analyser la r√©ponse pour extraire le JSON
                content = response.choices[0].message.content.strip()
                logger.info(f"ü§ñ Sc√®nes g√©n√©r√©es: {content[:100]}...")

                # Essayer de parser le JSON
                try:
                    scenes_data = json.loads(content)
                    return scenes_data
                except json.JSONDecodeError:
                    logger.error(f"Erreur parsing JSON OpenAI: r√©ponse invalide pour {num_scenes} sc√®nes")
                    raise Exception(f"OpenAI API a retourn√© un JSON invalide pour {num_scenes} sc√®nes")

            except Exception as api_error:
                logger.error(f"Erreur API OpenAI: {api_error}")
                raise Exception(f"√âchec g√©n√©ration sc√®nes: {api_error}")

        except Exception as e:
            logger.error(f"Erreur g√©n√©ration prompts adapt√©s: {e}")
            raise Exception(f"√âchec g√©n√©ration {num_scenes} sc√®nes: {e}")


    # NOTE: add_audio_to_clip et _wait_fal_audio supprim√©es car Veo 3.1 Fast g√©n√®re d√©j√† l'audio automatiquement
    # Les clips g√©n√©r√©s par Veo 3.1 Fast incluent d√©j√† l'audio, pas besoin d'ajout s√©par√©

    async def create_sora2_clip(self, scene_prompt: str, idea: str, environment: str) -> str:
        """
        Create Clips - G√©n√®re un clip vid√©o avec Runway ML Veo 3.1 Fast
        """
        logger.info(f"üé¨ D√©but create_sora2_clip - plateforme s√©lectionn√©e: {self.selected_platform}")
        try:
            platform = self.selected_platform
            platform_config = self.sora_platforms[platform]
            logger.info(f"üé¨ Platform config charg√©: {platform} - available: {platform_config.get('available', False)}")

            if platform != "runway":
                raise Exception(f"‚ùå Plateforme {platform} non support√©e - seule Runway ML est disponible")

            # Prompt pour Runway ML - limit√© √† 1000 caract√®res max
            # Format simplifi√© pour respecter la limite de l'API
            runway_prompt = f"{scene_prompt} in {environment}"
            
            # Limiter √† 1000 caract√®res si n√©cessaire
            if len(runway_prompt) > 1000:
                runway_prompt = runway_prompt[:997] + "..."

            logger.info(f"üé¨ G√©n√©ration Runway ML sc√®ne: {scene_prompt[:50]}...")
            logger.info(f"üìù Prompt longueur: {len(runway_prompt)} caract√®res")

            # V√©rification d√©taill√©e de la cl√© API
            api_key = platform_config['api_key']
            logger.info(f"üîç DEBUG - Platform config: {platform_config}")
            logger.info(f"üîç DEBUG - API key pr√©sente: {bool(api_key)}")
            logger.info(f"üîç DEBUG - API key longueur: {len(api_key) if api_key else 0}")
            logger.info(f"üîç DEBUG - API key commence par 'key_': {api_key.startswith('key_') if api_key else False}")
            logger.info(f"üîç DEBUG - API key pr√©fixe: {api_key[:10] if api_key else 'None'}")

            if not api_key:
                raise Exception("‚ùå RUNWAY_API_KEY non configur√©e dans les variables d'environnement Railway")
            if not api_key.startswith('key_'):
                raise Exception(f"‚ùå RUNWAY_API_KEY mal format√©e: doit commencer par 'key_' (actuellement: {api_key[:10]}...)")

            logger.info(f"‚úÖ Cl√© API Runway valide: {api_key[:20]}...")

            # Pr√©paration de la requ√™te pour Runway ML veo3.1_fast (text-to-video)
            # Utilisation de l'endpoint /v1/text_to_video (text-to-video pur)
            runway_payload = {
                "model": "veo3.1_fast",  # Veo 3.1 Fast - text-to-video
                "promptText": runway_prompt,  # Prompt texte pour g√©n√©ration directe
                "duration": 8,  # 8 secondes max pour veo3.1_fast (4, 6 ou 8)
                "ratio": "1920:1080",  # Format 16:9 en pixels (requis par API)
                "watermark": False
            }

            # Headers pour l'API Runway ML
            headers = {
                "Authorization": f"Bearer {platform_config['api_key']}",
                "Content-Type": "application/json",
                "X-Runway-Version": "2024-09-13"  # Version requise par l'API
            }

            # URL de l'API Runway ML - endpoint text_to_video pour veo3.1_fast
            api_url = f"{platform_config['base_url']}/v1/text_to_video"

            logger.info(f"üì° Appel API Runway ML: {api_url}")

            # Faire la requ√™te √† l'API Runway ML
            logger.info(f"üåê Requ√™te Runway ML: POST {api_url}")
            logger.info(f"üìã Headers: Authorization=Bearer {api_key[:20]}..., X-Runway-Version={headers.get('X-Runway-Version')}")
            logger.info(f"üì¶ Payload: {runway_payload}")

            async with aiohttp.ClientSession() as session:
                async with session.post(api_url, json=runway_payload, headers=headers) as response:
                    if response.status == 200:
                        response_data = await response.json()
                        task_id = response_data.get("id")
                        logger.info(f"‚úÖ T√¢che Runway ML cr√©√©e: {task_id}")

                        # Attendre que la g√©n√©ration soit termin√©e
                        video_url = await self._wait_for_runway_task(session, task_id, headers)
                        return video_url

                    else:
                        error_text = await response.text()
                        logger.error(f"‚ùå Erreur API Runway ML ({response.status}): {error_text}")
                        logger.error(f"üîç DEBUG - Headers de r√©ponse: {dict(response.headers)}")
                        logger.error(f"üîç DEBUG - URL compl√®te: {api_url}")
                        raise Exception(f"API Runway ML error: {response.status} - {error_text}")

        except Exception as e:
            logger.error(f"Erreur g√©n√©ration clip Runway ML: {e}")
            # √âchec d√©finitif - pas de fallback autoris√©
            raise Exception(f"√âchec g√©n√©ration vid√©o Runway ML: {e}")

    async def _wait_for_runway_task(self, session, task_id: str, headers: dict, max_wait: int = 300) -> str:
        """
        Attend qu'une t√¢che Runway ML soit termin√©e et retourne l'URL de la vid√©o
        """
        # Endpoint correct pour v√©rifier le statut d'une t√¢che
        api_url = f"https://api.dev.runwayml.com/v1/tasks/{task_id}"
        logger.info(f"üîç URL v√©rification statut: {api_url}")

        start_time = time.time()
        attempt = 0
        while time.time() - start_time < max_wait:
            try:
                attempt += 1
                async with session.get(api_url, headers=headers) as response:
                    if response.status == 200:
                        task_data = await response.json()

                        status = task_data.get("status")
                        progress = task_data.get("progress", 0)
                        logger.info(f"üìä Statut t√¢che Runway ML (tentative {attempt}): {status} - Progression: {progress}%")

                        if status == "SUCCEEDED":
                            # R√©cup√©rer l'URL de la vid√©o g√©n√©r√©e
                            output = task_data.get("output", [])
                            if output and len(output) > 0:
                                video_url = output[0]
                                logger.info(f"‚úÖ Vid√©o Runway ML g√©n√©r√©e: {video_url}")
                                # Indentation corrig√©e pour √©viter IndentationError
                                return video_url
                            else:
                                logger.error(f"‚ùå Pas de vid√©o dans la r√©ponse: {task_data}")
                                raise Exception("No video URL in Runway ML response")

                        elif status == "FAILED":
                            error_msg = task_data.get("failure", "Erreur inconnue")
                            logger.error(f"‚ùå √âchec g√©n√©ration Runway ML: {error_msg}")
                            logger.error(f"üîç D√©tails: {task_data}")
                            raise Exception(f"Runway ML generation failed: {error_msg}")

                        # Attendre avant de v√©rifier √† nouveau
                        await asyncio.sleep(10)

                    else:
                        error_text = await response.text()
                        logger.warning(f"‚ö†Ô∏è Erreur v√©rification statut ({response.status}): {error_text[:200]}")
                        await asyncio.sleep(5)

            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Erreur lors de la v√©rification (tentative {attempt}): {e}")
                await asyncio.sleep(5)

        # Timeout
        logger.error(f"‚è∞ Timeout g√©n√©ration Runway ML apr√®s {max_wait}s")
        raise Exception(f"Runway ML generation timeout after {max_wait} seconds")

    async def sequence_sora2_video(self, video_urls: List[str]) -> str:
        """
        Sequence Video - Assemble les clips avec l'API Runway ML ou FAL AI
        """
        try:
            logger.info(f"üîó Assemblage de {len(video_urls)} clips vid√©o...")

            if len(video_urls) == 0:
                raise Exception("Aucun clip √† assembler")

            if len(video_urls) == 1:
                logger.info("‚úÖ Un seul clip - pas d'assemblage n√©cessaire")
                return video_urls[0]

            platform = self.selected_platform

            # Essayer d'abord Runway ML pour l'assemblage (si disponible)
            if platform == "runway":
                try:
                    logger.info("üîß Tentative assemblage avec Runway ML...")
                    return await self._assemble_with_runway(video_urls)
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è Assemblage Runway ML √©chou√©: {e}")
                    logger.info("üîÑ Basculement vers FAL AI pour l'assemblage...")

            # Utiliser FAL AI pour l'assemblage (fallback ou m√©thode principale)
            logger.info("üîß Assemblage avec FAL AI...")
            try:
                final_url = await self._assemble_with_fal(video_urls)
                logger.info(f"‚úÖ Assemblage FAL AI r√©ussi: {final_url}")
                return final_url
            except Exception as e:
                logger.error(f"‚ùå Assemblage FAL AI √©chou√©: {e}")
                raise Exception(f"√âchec assemblage vid√©o FAL AI: {e}")

        except Exception as e:
            logger.error(f"Erreur assemblage vid√©o: {e}")
            raise Exception(f"√âchec assemblage vid√©o complet: {e}")

    async def _assemble_with_runway(self, video_urls: List[str]) -> str:
        """
        Assemblage avec l'API Runway ML
        """
        try:
            platform_config = self.sora_platforms["runway"]
            api_key = platform_config['api_key']
            # La cl√© contient d√©j√† le pr√©fixe 'key_', ne pas le dupliquer
            headers = {
                "Authorization": f"Bearer {api_key}",
                "Content-Type": "application/json",
                "X-Runway-Version": "2024-09-13"  # Version requise par l'API
            }

            # Pr√©parer les keyframes pour Runway ML
            keyframes = []
            current_time = 0
            clip_duration = 10  # 10 secondes par clip

            for i, video_url in enumerate(video_urls):
                keyframes.append({
                    "url": video_url,
                    "timestamp": current_time,
                    "duration": clip_duration
                })
                current_time += clip_duration

            payload = {
                "model": "veo3.1_fast",  # ou un mod√®le d'assemblage si disponible
                "keyframes": keyframes,
                "width": 1920,
                "height": 1080,
                "fps": 24
            }

            api_url = f"{platform_config['base_url']}/assemble"  # Endpoint hypoth√©tique
            logger.info(f"üì° Appel API Runway ML assemble: {api_url}")

            async with aiohttp.ClientSession() as session:
                async with session.post(api_url, json=payload, headers=headers) as response:
                    if response.status == 200:
                        result = await response.json()
                        task_id = result.get("id")

                        # Attendre la fin de l'assemblage
                        return await self._wait_runway_assemble(session, task_id, headers)
                    else:
                        error_text = await response.text()
                        raise Exception(f"Runway assemble API error: {response.status} - {error_text}")

        except Exception as e:
            logger.error(f"Erreur assemblage Runway ML: {e}")
            raise

    async def _assemble_with_fal(self, video_urls: List[str]) -> str:
        """
        Assemblage avec FAL AI FFmpeg
        """
        try:
            fal_key = os.getenv("FAL_API_KEY")
            if not fal_key:
                raise Exception("FAL_API_KEY non configur√©e")

            headers = {
                "Authorization": f"Key {fal_key}",
                "Content-Type": "application/json"
            }

            # Pr√©parer les tracks pour FAL AI FFmpeg
            tracks = []
            current_time = 0
            clip_duration = 10  # 10 secondes par clip

            for i, video_url in enumerate(video_urls):
                tracks.append({
                    "id": f"clip_{i+1}",
                    "type": "video",
                    "keyframes": [{
                        "url": video_url,
                        "timestamp": current_time,
                        "duration": clip_duration
                    }]
                })
                current_time += clip_duration

            payload = {
                "tracks": tracks,
                "output_format": "mp4",
                "resolution": "1080p",
                "frame_rate": 24
            }

            api_url = "https://queue.fal.run/fal-ai/ffmpeg-api/compose"
            logger.info(f"üì° Appel FAL AI assemble: {api_url}")

            async with aiohttp.ClientSession() as session:
                async with session.post(api_url, json=payload, headers=headers) as response:
                    if response.status == 200:
                        result = await response.json()
                        request_id = result.get("request_id")

                        # Attendre la fin de l'assemblage
                        return await self._wait_fal_assemble(session, request_id, headers)
                    else:
                        error_text = await response.text()
                        raise Exception(f"FAL assemble API error: {response.status} - {error_text}")

        except Exception as e:
            logger.error(f"Erreur assemblage FAL AI: {e}")
            raise

    async def _wait_runway_assemble(self, session, task_id: str, headers: dict, max_wait: int = 300) -> str:
        """
        Attendre qu'un assemblage Runway ML soit termin√©
        """
        api_url = f"https://api.dev.runwayml.com/v1/tasks/{task_id}"
        start_time = time.time()

        while time.time() - start_time < max_wait:
            try:
                async with session.get(api_url, headers=headers) as response:
                    if response.status == 200:
                        task_data = await response.json()
                        status = task_data.get("status")

                        if status == "SUCCEEDED":
                            return task_data.get("output_url", task_data.get("video_url"))
                        elif status == "FAILED":
                            raise Exception(f"Assemblage Runway ML √©chou√©: {task_data.get('error')}")

                    await asyncio.sleep(10)

            except Exception as e:
                logger.warning(f"Erreur v√©rification assemblage Runway: {e}")
                await asyncio.sleep(5)

        raise Exception(f"Timeout assemblage Runway ML apr√®s {max_wait}s")

    async def _wait_fal_assemble(self, session, request_id: str, headers: dict, max_wait: int = 300) -> str:
        """
        Attendre qu'un assemblage FAL AI soit termin√©
        """
        api_url = f"https://queue.fal.run/fal-ai/ffmpeg-api/requests/{request_id}"
        start_time = time.time()

        while time.time() - start_time < max_wait:
            try:
                async with session.get(api_url, headers=headers) as response:
                    if response.status == 200:
                        result = await response.json()
                        status = result.get("status")

                        if status == "COMPLETED":
                            return result.get("video_url") or result.get("output_url")
                        elif status == "FAILED":
                            raise Exception(f"Assemblage FAL AI √©chou√©: {result.get('error')}")

                    await asyncio.sleep(10)

            except Exception as e:
                logger.warning(f"Erreur v√©rification assemblage FAL: {e}")
                await asyncio.sleep(5)

        raise Exception(f"Timeout assemblage FAL AI apr√®s {max_wait}s")

    async def generate_complete_animation_zseedance(self, theme: str = "space", duration: int = 30, style: str = "cartoon") -> Dict[str, Any]:
        """
        Pipeline complet bas√© exactement sur zseedance.json
        G√©n√®re un nombre de sc√®nes adapt√© √† la dur√©e demand√©e (10s par sc√®ne)
        """
        logger.info(f"üé¨ ZSEEDANCE: D√©marrage g√©n√©ration compl√®te - th√®me: {theme}, dur√©e: {duration}s, style: {style}")
        try:
            logger.info(f"üöÄ D√©marrage g√©n√©ration ZSEEDANCE: {theme} ({duration}s, style: {style})")

            # Calculer le nombre de sc√®nes selon la dur√©e (8s par sc√®ne avec veo3.1_fast)
            # Arrondir pour √™tre plus proche de la dur√©e demand√©e
            num_scenes = max(3, round(duration / 8))  # Minimum 3 sc√®nes, ~8s par sc√®ne
            total_duration = num_scenes * 8
            logger.info(f"üìä G√©n√©ration de {num_scenes} sc√®nes de 8 secondes chacune (dur√©e totale: {total_duration}s pour {duration}s demand√©s)")

            # √âtape 1: Ideas AI Agent avec adaptation au th√®me choisi
            logger.info("üìù √âtape 1: Ideas AI Agent (adapt√© au th√®me)...")
            idea_data = await self.generate_ideas_agent_adapted(theme)
            logger.info(f"‚úÖ √âtape 1 termin√©e: {idea_data.get('Idea', 'N/A')[:50]}...")

            # √âtape 2: Prompts AI Agent adapt√© pour g√©n√©rer le bon nombre de sc√®nes
            logger.info(f"üìù √âtape 2: Prompts AI Agent ({num_scenes} sc√®nes)...")
            prompts_data = await self.generate_prompts_agent_adapted(idea_data, num_scenes)
            logger.info(f"‚úÖ √âtape 2 termin√©e: {num_scenes} sc√®nes g√©n√©r√©es")

            # √âtape 3: Create Clips avec Veo 3.1 Fast
            logger.info("üé¨ √âtape 3: Create Clips avec Veo 3.1 Fast...")
            video_urls = []

            # G√©n√©rer les clips selon le nombre calcul√©
            for i in range(1, num_scenes + 1):
                logger.info(f"üé¨ G√©n√©ration clip {i}/{num_scenes}...")
                scene_key = f"Scene {i}"
                if scene_key in prompts_data:
                    scene_prompt = prompts_data[scene_key]
                    logger.info(f"üé¨ G√©n√©ration sc√®ne {i}/{num_scenes}: {scene_prompt[:50]}...")

                    # Attendre entre les g√©n√©rations (comme zseedance avec batching)
                    if i > 1:
                        await asyncio.sleep(3)

                    video_url = await self.create_sora2_clip(
                        scene_prompt,
                        prompts_data["Idea"],
                        prompts_data["Environment"]
                    )
                    video_urls.append(video_url)

            # √âtape 4: Sequence Video - Assemblage final
            # Note: Veo 3.1 Fast g√©n√®re d√©j√† l'audio automatiquement, pas besoin d'ajout audio s√©par√©
            logger.info("üîó √âtape 4: Sequence Video (assemblage final des clips avec audio int√©gr√©)...")
            final_video_url = await self.sequence_sora2_video(video_urls)

            logger.info("‚úÖ Animation ZSEEDANCE termin√©e avec succ√®s!")

            return {
                "status": "completed",
                "final_video_url": final_video_url,
                "title": f"üé¨ {idea_data['Idea']}",
                "duration": duration,
                "theme": theme,
                "style": style,
                "type": "zseedance_complete",
                "platform": self.selected_platform,
                "scenes_count": num_scenes,
                "video_count": len(video_urls),
                "idea": idea_data,
                "prompts": prompts_data,
                "generated_at": datetime.now().isoformat(),
                "clips": [
                    {
                        "scene_number": i + 1,
                        "video_url": video_urls[i],
                        "duration": 8,  # 8 secondes par clip
                        "status": "success"
                    }
                    for i in range(len(video_urls))
                ]
            }

        except Exception as e:
            logger.error(f"‚ùå Erreur g√©n√©ration Veo 3.1 Fast zseedance: {e}")
            return {
                "status": "failed",
                "error": str(e),
                "theme": theme,
                "type": "veo3_1_fast_zseedance",
                "platform": self.selected_platform
            }

    def is_available(self) -> bool:
        """V√©rifie si au moins une plateforme Veo 3.1 Fast est disponible"""
        return any(config["available"] for config in self.sora_platforms.values())

    def get_available_platforms(self) -> List[str]:
        """Retourne la liste des plateformes Veo 3.1 Fast disponibles"""
        return [name for name, config in self.sora_platforms.items() if config["available"]]


# Instance globale du g√©n√©rateur Veo 3.1 Fast zseedance
sora2_zseedance_generator = Sora2ZseedanceGenerator()
