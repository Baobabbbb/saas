"""
Service d'Animation avec CrewAI - √âquipe Multi-Agents
G√©n√©ration automatique de dessins anim√©s √† partir de texte narratif
Architecture: Sc√©nariste ‚Üí Directeur Artistique ‚Üí Prompt Engineer ‚Üí Op√©rateur Technique ‚Üí Monteur Vid√©o
"""

import os
import json
import asyncio
import aiohttp
import time
import uuid
from typing import Dict, List, Any, Optional
from datetime import datetime
from pathlib import Path
from dataclasses import dataclass
from dotenv import load_dotenv

# Charger les variables d'environnement CrewAI
load_dotenv('.env.crewai')

# Imports CrewAI
from crewai import Agent, Task, Crew, Process
from langchain_openai import ChatOpenAI

# Video processing
from moviepy.editor import VideoFileClip, concatenate_videoclips, ColorClip
import requests

@dataclass
class AnimationScene:
    """Structure d'une sc√®ne d'animation"""
    scene_number: int
    description: str
    duration: float
    action: str
    setting: str
    visual_prompt: Optional[str] = None
    seed: Optional[str] = None
    video_url: Optional[str] = None
    local_path: Optional[str] = None
    status: str = "pending"

@dataclass
class VisualStyle:
    """Direction artistique pour l'animation"""
    global_style: str
    color_palette: List[str]
    characters_style: str
    settings_style: str
    mood: str
    keywords: List[str]
    character_seeds: Dict[str, str]
    setting_seeds: Dict[str, str]

class AnimationCrewAIService:
    """Service complet de g√©n√©ration d'animation avec √©quipe CrewAI"""
    
    def __init__(self):
        self.openai_api_key = os.getenv("OPENAI_API_KEY")
        self.stability_api_key = os.getenv("STABILITY_API_KEY") 
        self.cache_dir = Path("cache/crewai_animations")
        self.cache_dir.mkdir(parents=True, exist_ok=True)
        
        # Configuration CrewAI
        try:
            self.llm = ChatOpenAI(
                openai_api_key=self.openai_api_key or "dummy",
                model="gpt-4"
            )
        except Exception as e:
            print(f"‚ö†Ô∏è Erreur configuration LLM: {e}")
            self.llm = None
        
        print("Service Animation CrewAI initialise")
        print(f"Cache: {self.cache_dir}")
    
    def create_agents(self) -> Dict[str, Agent]:
        """Cr√©er l'√©quipe d'agents CrewAI sp√©cialis√©s"""
        
        agents = {}
        
        # üß© Agent 1: Sc√©nariste
        agents['screenwriter'] = Agent(
            role="Sc√©nariste Expert en Animation",
            goal="D√©couper une histoire en segments courts et visuels parfaits pour l'animation (5-15s chacun)",
            backstory="""Tu es un sc√©nariste exp√©riment√© sp√©cialis√© dans l'animation pour enfants. 
            Tu excelles √† transformer une histoire narrative en s√©quence de sc√®nes visuelles captivantes.
            Tu comprends le rythme de l'animation et sais identifier les moments-cl√©s qui feront de bonnes sc√®nes.
            Tu adaptes automatiquement pour les enfants de 3 √† 8 ans avec un storytelling fluide.""",
            verbose=True,
            allow_delegation=False,
            llm=self.llm
        )
        
        # üé® Agent 2: Directeur Artistique
        agents['art_director'] = Agent(
            role="Directeur Artistique et Responsable Coh√©rence Visuelle",
            goal="D√©finir un style visuel unifi√© et cr√©er des seeds pour garantir la coh√©rence des personnages et d√©cors",
            backstory="""Tu es un directeur artistique expert en animation 2D/3D pour enfants.
            Tu d√©finis des palettes harmonieuses, des styles coh√©rents et tu cr√©es des 'seeds' sp√©cifiques
            pour chaque personnage et d√©cor afin d'assurer une continuit√© visuelle parfaite d'une sc√®ne √† l'autre.
            Tu connais les techniques pour maintenir l'identit√© visuelle dans la g√©n√©ration IA.""",
            verbose=True,
            allow_delegation=False,
            llm=self.llm
        )
        
        # üß† Agent 3: Prompt Engineer
        agents['prompt_engineer'] = Agent(
            role="Prompt Engineer Expert en G√©n√©ration Vid√©o IA",
            goal="Transformer chaque sc√®ne en prompts riches et pr√©cis pour Stable Diffusion Video avec seeds appropri√©s",
            backstory="""Tu es expert en g√©n√©ration vid√©o par IA, sp√©cialis√© dans Stable Diffusion Video.
            Tu sais cr√©er des prompts d√©taill√©s qui produisent des animations de qualit√©, en int√©grant
            personnages, actions, d√©cors, ambiance et style de fa√ßon optimale.
            Tu ma√Ætrises l'usage des seeds pour la coh√©rence visuelle.""",
            verbose=True,
            allow_delegation=False,
            llm=self.llm
        )
        
        # üì° Agent 4: Op√©rateur Technique
        agents['technical_operator'] = Agent(
            role="Op√©rateur Technique et Gestionnaire API",
            goal="Orchestrer les appels API de g√©n√©ration vid√©o et s'assurer de la qualit√© des rendus",
            backstory="""Tu es un technicien expert en APIs de g√©n√©ration vid√©o.
            Tu g√®res les appels techniques, optimises les param√®tres de g√©n√©ration,
            g√®res les erreurs et t'assures que chaque clip vid√©o est g√©n√©r√© correctement.
            Tu connais les limites techniques et sais adapter les requ√™tes.""",
            verbose=True,
            allow_delegation=False,
            llm=self.llm
        )
        
        # üé¨ Agent 5: Monteur Vid√©o
        agents['video_editor'] = Agent(
            role="Monteur Vid√©o et Assembleur Final",
            goal="Assembler tous les clips dans l'ordre narratif pour cr√©er une vid√©o fluide et homog√®ne",
            backstory="""Tu es un monteur vid√©o sp√©cialis√© dans l'animation pour enfants.
            Tu connais le rythme narratif, les transitions fluides et tu sais cr√©er
            une exp√©rience visuelle coh√©rente √† partir de clips individuels.
            Tu optimises la dur√©e finale pour respecter les contraintes (30s-5min).""",
            verbose=True,
            allow_delegation=False,
            llm=self.llm
        )
        
        return agents
    
    def create_tasks(self, story_text: str, style_preferences: Dict[str, str], agents: Dict[str, Agent]) -> List[Task]:
        """Cr√©er les t√¢ches pour l'√©quipe d'agents"""
        
        tasks = []
        
        # üìã T√¢che 1: D√©coupage Narratif
        scenario_task = Task(
            description=f"""
            MISSION: Analyser cette histoire et la d√©couper en sc√®nes visuelles optimales pour l'animation.
            
            HISTOIRE √Ä ANALYSER: {story_text}
            
            CONTRAINTES:
            - Cr√©er 4 √† 12 sc√®nes de 5 √† 15 secondes chacune
            - Dur√©e totale: entre 30 secondes et 5 minutes maximum
            - Chaque sc√®ne doit √™tre visuellement claire et captivante
            - Progression narrative fluide et logique
            - Adapt√© aux enfants de 3 √† 8 ans
            - Identifier les personnages principaux et les d√©cors r√©currents
            
            FORMAT JSON OBLIGATOIRE:
            {{
                "story_analysis": {{
                    "main_characters": ["personnage1", "personnage2"],
                    "main_settings": ["d√©cor1", "d√©cor2"],
                    "narrative_arc": "description de l'arc narratif"
                }},
                "scenes": [
                    {{
                        "scene_number": 1,
                        "duration": 8,
                        "description": "Description visuelle pr√©cise de la sc√®ne",
                        "action": "Action principale visible √† l'√©cran",
                        "setting": "D√©cor/lieu de la sc√®ne",
                        "characters": ["personnages pr√©sents"],
                        "visual_focus": "√âl√©ment visuel principal"
                    }}
                ],
                "total_scenes": 5,
                "estimated_duration": 40,
                "narrative_coherence": "Explication de la coh√©rence narrative"
            }}
            """,
            agent=agents['screenwriter'],
            expected_output="D√©coupage narratif structur√© en JSON avec analyse compl√®te"
        )
        
        # üé® T√¢che 2: Direction Artistique et Seeds
        art_direction_task = Task(
            description=f"""
            MISSION: D√©finir la direction artistique compl√®te avec seeds pour la coh√©rence visuelle.
            
            STYLE DEMAND√â: {style_preferences}
            
            CONTRAINTES:
            - Style visuel coh√©rent et attractif pour enfants 3-8 ans
            - Palette de couleurs harmonieuse
            - Cr√©er des seeds sp√©cifiques pour chaque personnage et d√©cor
            - Assurer la continuit√© visuelle entre toutes les sc√®nes
            - Style adapt√© √† la g√©n√©ration vid√©o IA
            
            FORMAT JSON OBLIGATOIRE:
            {{
                "visual_style": {{
                    "global_style": "Description du style g√©n√©ral (ex: cartoon 3D color√©)",
                    "color_palette": ["#couleur1", "#couleur2", "#couleur3"],
                    "mood": "ambiance g√©n√©rale (joyeux, aventureux, etc.)",
                    "art_keywords": ["cartoon", "colorful", "child-friendly", "smooth"]
                }},
                "character_design": {{
                    "characters_style": "Description du style des personnages",
                    "character_seeds": {{
                        "personnage1": "seed_unique_123",
                        "personnage2": "seed_unique_456"
                    }}
                }},
                "environment_design": {{
                    "settings_style": "Description du style des d√©cors",
                    "setting_seeds": {{
                        "d√©cor1": "seed_env_789",
                        "d√©cor2": "seed_env_012"
                    }}
                }},
                "consistency_guidelines": "Instructions pour maintenir la coh√©rence visuelle"
            }}
            """,
            agent=agents['art_director'],
            expected_output="Direction artistique compl√®te avec seeds pour coh√©rence",
            context=[scenario_task]
        )
        
        # üß† T√¢che 3: G√©n√©ration de Prompts Optimis√©s
        prompt_engineering_task = Task(
            description="""
            MISSION: Cr√©er des prompts optimis√©s pour Stable Diffusion Video avec seeds appropri√©s.
            
            CONTRAINTES TECHNIQUES:
            - Prompts d√©taill√©s mais concis pour la g√©n√©ration vid√©o
            - Int√©grer le style visuel et les seeds de coh√©rence
            - Optimis√© pour Stable Diffusion Video
            - √âviter les termes incompatibles avec l'IA de g√©n√©ration
            - Assurer la fluidit√© d'animation entre les sc√®nes
            
            FORMAT JSON OBLIGATOIRE:
            {{
                "video_prompts": [
                    {{
                        "scene_number": 1,
                        "prompt": "Prompt d√©taill√© pour Stable Diffusion Video",
                        "duration": 8,
                        "seed": "seed_appropri√©",
                        "style_keywords": "mots-cl√©s de style sp√©cifiques",
                        "technical_params": {{
                            "motion": "medium",
                            "aspect_ratio": "16:9",
                            "fps": 24
                        }}
                    }}
                ],
                "global_style_prompt": "Style g√©n√©ral √† maintenir sur toutes les sc√®nes",
                "consistency_instructions": "Instructions pour maintenir la coh√©rence"
            }}
            """,
            agent=agents['prompt_engineer'],
            expected_output="Prompts optimis√©s pour g√©n√©ration vid√©o avec param√®tres techniques",
            context=[scenario_task, art_direction_task]
        )
        
        # üì° T√¢che 4: Orchestration Technique
        technical_task = Task(
            description="""
            MISSION: Planifier et orchestrer la g√©n√©ration vid√©o de toutes les sc√®nes.
            
            RESPONSABILIT√âS:
            - Analyser les prompts et param√®tres techniques
            - Planifier l'ordre de g√©n√©ration optimal
            - Pr√©voir la gestion des erreurs et reprises
            - Optimiser les ressources et le temps de g√©n√©ration
            - Valider la qualit√© attendue de chaque clip
            
            FORMAT JSON OBLIGATOIRE:
            {{
                "generation_plan": {{
                    "total_clips": 5,
                    "estimated_time": "15-20 minutes",
                    "generation_order": [1, 2, 3, 4, 5],
                    "parallel_possible": false
                }},
                "technical_validation": {{
                    "all_prompts_valid": true,
                    "seeds_assigned": true,
                    "durations_optimal": true,
                    "style_consistent": true
                }},
                "fallback_strategy": {{
                    "backup_prompts": "Strat√©gie en cas d'√©chec",
                    "quality_thresholds": "Seuils de qualit√© minimum"
                }},
                "execution_ready": true
            }}
            """,
            agent=agents['technical_operator'],
            expected_output="Plan d'ex√©cution technique valid√©",
            context=[prompt_engineering_task]
        )
        
        # üé¨ T√¢che 5: Plan de Montage
        editing_task = Task(
            description="""
            MISSION: Planifier l'assemblage final et les transitions entre sc√®nes.
            
            OBJECTIFS:
            - Cr√©er un plan de montage fluide et rythm√©
            - D√©finir les transitions entre sc√®nes
            - Optimiser la dur√©e finale (30s-5min)
            - Assurer la coh√©rence narrative et visuelle
            - Pr√©voir les ajustements post-g√©n√©ration
            
            FORMAT JSON OBLIGATOIRE:
            {{
                "editing_plan": {{
                    "total_duration": 45,
                    "scene_transitions": [
                        {{
                            "from_scene": 1,
                            "to_scene": 2,
                            "transition_type": "cut/fade/dissolve",
                            "transition_duration": 0.5
                        }}
                    ]
                }},
                "rhythm_analysis": {{
                    "pacing": "Description du rythme narratif",
                    "climax_placement": "Positionnement du point culminant",
                    "emotional_arc": "Arc √©motionnel de l'animation"
                }},
                "post_processing": {{
                    "color_correction": "Corrections colorim√©triques n√©cessaires",
                    "audio_sync": "Synchronisation audio si applicable",
                    "final_adjustments": "Ajustements finaux pr√©vus"
                }},
                "export_settings": {{
                    "format": "MP4",
                    "resolution": "1920x1080",
                    "fps": 24,
                    "bitrate": "high"
                }}
            }}
            """,
            agent=agents['video_editor'],
            expected_output="Plan de montage complet et optimis√©",
            context=[scenario_task, art_direction_task, technical_task]
        )
        
        tasks.extend([scenario_task, art_direction_task, prompt_engineering_task, technical_task, editing_task])
        
        return tasks
    
    async def call_video_generation_api(self, prompt: str, duration: int = 8, seed: Optional[str] = None) -> Dict[str, Any]:
        """Appel √† l'API de g√©n√©ration vid√©o (Stable Diffusion Video ou √©quivalent)"""
        
        if not self.stability_api_key:
            # Mode simulation pour les tests
            print(f"üé≠ Mode simulation - G√©n√©ration: {prompt[:50]}...")
            await asyncio.sleep(2)  # Simuler le temps de g√©n√©ration
            
            return {
                "id": f"sim_video_{uuid.uuid4().hex[:8]}",
                "status": "success",
                "video_url": f"https://example.com/simulated_video_{seed or 'noseed'}.mp4",
                "duration": duration,
                "prompt": prompt,
                "seed": seed
            }
        
        # Configuration pour l'API r√©elle (Stability AI ou √©quivalent)
        headers = {
            "Authorization": f"Bearer {self.stability_api_key}",
            "Content-Type": "application/json"
        }
        
        payload = {
            "prompt": prompt,
            "duration": min(duration, 15),  # Max 15s par clip
            "seed": seed,
            "motion": "medium",
            "aspect_ratio": "16:9",
            "fps": 24
        }
        
        try:
            async with aiohttp.ClientSession() as session:
                # API endpoint pour Stability AI Video
                async with session.post(
                    "https://api.stability.ai/v2alpha/generation/video",
                    headers=headers,
                    json=payload
                ) as response:
                    
                    if response.status != 200:
                        raise Exception(f"Erreur API Video: {response.status}")
                    
                    result = await response.json()
                    task_id = result.get("id")
                    
                    if not task_id:
                        raise Exception("Pas d'ID de t√¢che retourn√©")
                    
                    # Attendre la compl√©tion (polling)
                    max_wait = 180  # 3 minutes max par clip
                    wait_time = 0
                    
                    while wait_time < max_wait:
                        await asyncio.sleep(10)
                        wait_time += 10
                        
                        # V√©rifier le statut
                        async with session.get(
                            f"https://api.stability.ai/v2alpha/generation/video/{task_id}",
                            headers=headers
                        ) as status_response:
                            
                            if status_response.status == 200:
                                status_data = await status_response.json()
                                
                                if status_data.get("status") == "completed":
                                    return {
                                        "id": task_id,
                                        "status": "success",
                                        "video_url": status_data.get("video", {}).get("url"),
                                        "duration": duration,
                                        "prompt": prompt,
                                        "seed": seed
                                    }
                                elif status_data.get("status") == "failed":
                                    raise Exception(f"G√©n√©ration √©chou√©e: {status_data.get('error', 'Erreur inconnue')}")
                    
                    raise Exception("Timeout: g√©n√©ration trop longue")
                    
        except Exception as e:
            print(f"‚ùå Erreur API Vid√©o: {e}")
            # Retourner un r√©sultat de simulation en cas d'erreur
            return {
                "id": f"fallback_video_{uuid.uuid4().hex[:8]}",
                "status": "fallback",
                "video_url": None,
                "duration": duration,
                "error": str(e),
                "prompt": prompt,
                "seed": seed
            }
    
    async def download_video(self, video_url: str, scene_number: int) -> str:
        """T√©l√©charger une vid√©o g√©n√©r√©e"""
        
        if not video_url or video_url.startswith("https://example.com"):
            # Mode simulation - cr√©er un fichier factice
            fake_path = self.cache_dir / f"scene_{scene_number}_simulation.mp4"
            fake_path.touch()
            return str(fake_path)
        
        local_path = self.cache_dir / f"scene_{scene_number}_{int(time.time())}.mp4"
        
        try:
            async with aiohttp.ClientSession() as session:
                async with session.get(video_url) as response:
                    if response.status == 200:
                        with open(local_path, 'wb') as f:
                            async for chunk in response.content.iter_chunked(8192):
                                f.write(chunk)
                        
                        print(f"‚úÖ Vid√©o t√©l√©charg√©e: {local_path}")
                        return str(local_path)
                    else:
                        raise Exception(f"Erreur t√©l√©chargement: {response.status}")
                        
        except Exception as e:
            print(f"‚ùå Erreur t√©l√©chargement vid√©o: {e}")
            # Cr√©er un fichier factice en cas d'erreur
            fake_path = self.cache_dir / f"scene_{scene_number}_error.mp4"
            fake_path.touch()
            return str(fake_path)
    
    def assemble_final_animation(self, animation_scenes: List[AnimationScene], output_path: str, editing_plan: Dict[str, Any]) -> str:
        """Assembler les vid√©os en animation finale selon le plan de montage"""
        
        try:
            clips = []
            
            for scene in animation_scenes:
                if scene.local_path and os.path.exists(scene.local_path):
                    # Si c'est un fichier factice (simulation), cr√©er un clip color√©
                    if os.path.getsize(scene.local_path) == 0:
                        print(f"üé≠ Clip de simulation pour sc√®ne {scene.scene_number}")
                        # Cr√©er un clip color√© avec texte pour simulation
                        colors = [(100, 150, 200), (200, 100, 150), (150, 200, 100), (200, 150, 100), (100, 200, 150)]
                        color = colors[scene.scene_number % len(colors)]
                        clip = ColorClip(size=(1920, 1080), color=color, duration=scene.duration)
                    else:
                        clip = VideoFileClip(scene.local_path)
                        
                        # Ajuster la dur√©e si n√©cessaire
                        if clip.duration != scene.duration:
                            clip = clip.subclip(0, min(clip.duration, scene.duration))
                    
                    clips.append(clip)
                    print(f"‚úÖ Clip ajout√©: Sc√®ne {scene.scene_number} ({scene.duration}s)")
            
            if not clips:
                raise Exception("Aucun clip vid√©o disponible pour l'assemblage")
            
            # Assembler selon le plan de montage
            transitions = editing_plan.get("editing_plan", {}).get("scene_transitions", [])
            
            # Pour l'instant, assemblage simple (transitions avanc√©es √† impl√©menter)
            final_animation = concatenate_videoclips(clips, method="compose")
            
            # Exporter l'animation finale
            final_animation.write_videofile(
                output_path,
                fps=24,
                codec='libx264',
                audio_codec=None,  # Pas d'audio pour l'instant
                temp_audiofile=str(self.cache_dir / "temp_audio.wav"),
                remove_temp=True,
                verbose=False,
                logger=None
            )
            
            # Nettoyer les clips
            for clip in clips:
                clip.close()
            final_animation.close()
            
            print(f"üé¨ Animation finale assembl√©e: {output_path}")
            return output_path
            
        except Exception as e:
            print(f"‚ùå Erreur assemblage animation: {e}")
            raise Exception(f"√âchec assemblage animation: {str(e)}")
    
    async def generate_complete_animation(self, story_text: str, style_preferences: Optional[Dict[str, str]] = None) -> Dict[str, Any]:
        """G√©n√©ration compl√®te d'une animation narrative avec √©quipe CrewAI"""
        
        start_time = time.time()
        
        if style_preferences is None:
            style_preferences = {
                "style": "cartoon 3D color√©",
                "mood": "joyeux et aventureux",
                "target_age": "3-8 ans",
                "theme": "√©ducatif et divertissant"
            }
        
        print(f"üé¨ === D√âBUT G√âN√âRATION ANIMATION CREWAI ===")
        print(f"üìù Histoire: {story_text[:100]}...")
        print(f"üé® Style: {style_preferences}")
        
        try:
            # 1. Cr√©er l'√©quipe d'agents
            agents = self.create_agents()
            print(f"üë• {len(agents)} agents cr√©√©s")
            
            # 2. Cr√©er les t√¢ches
            tasks = self.create_tasks(story_text, style_preferences, agents)
            print(f"üìã {len(tasks)} t√¢ches cr√©√©es")
            
            # 3. Cr√©er l'√©quipe CrewAI
            crew = Crew(
                agents=list(agents.values()),
                tasks=tasks,
                process=Process.sequential,
                verbose=True,
                memory=True  # Activer la m√©moire pour la coh√©rence
            )
            
            # 4. Ex√©cuter le pipeline CrewAI
            print("üöÄ Lancement pipeline CrewAI...")
            crew_result = crew.kickoff()
            
            # 5. Parser les r√©sultats des agents
            print("üîç Analyse des r√©sultats CrewAI...")
            
            # Extraire les r√©sultats de chaque agent
            tasks_output = crew_result.tasks_output
            
            # Sc√©nariste (t√¢che 0)
            scenario_result = self._parse_json_result(tasks_output[0].raw if tasks_output else "{}")
            scenes_data = scenario_result.get("scenes", [])
            
            # Directeur Artistique (t√¢che 1)
            art_result = self._parse_json_result(tasks_output[1].raw if len(tasks_output) > 1 else "{}")
            visual_style = art_result
            
            # Prompt Engineer (t√¢che 2)
            prompt_result = self._parse_json_result(tasks_output[2].raw if len(tasks_output) > 2 else "{}")
            video_prompts = prompt_result.get("video_prompts", [])
            
            # Plan de montage (t√¢che 4)
            editing_result = self._parse_json_result(tasks_output[4].raw if len(tasks_output) > 4 else "{}")
            
            print(f"üé• {len(video_prompts)} sc√®nes √† g√©n√©rer")
            
            # 6. G√©n√©rer les vid√©os pour chaque sc√®ne
            animation_scenes = []
            
            for i, prompt_data in enumerate(video_prompts):
                scene_num = prompt_data.get("scene_number", i + 1)
                prompt = prompt_data.get("prompt", "")
                duration = prompt_data.get("duration", 8)
                seed = prompt_data.get("seed", None)
                
                print(f"üé¨ G√©n√©ration sc√®ne {scene_num}: {prompt[:50]}...")
                
                # Trouver les donn√©es de sc√®ne correspondantes
                scene_data = next((s for s in scenes_data if s.get("scene_number") == scene_num), {})
                
                # Appel API g√©n√©ration vid√©o
                video_result = await self.call_video_generation_api(prompt, duration, seed)
                
                # Cr√©er l'objet AnimationScene
                scene = AnimationScene(
                    scene_number=scene_num,
                    description=scene_data.get("description", prompt),
                    duration=duration,
                    action=scene_data.get("action", ""),
                    setting=scene_data.get("setting", ""),
                    visual_prompt=prompt,
                    seed=seed,
                    video_url=video_result.get("video_url"),
                    status="generated" if video_result.get("status") == "success" else "error"
                )
                
                # T√©l√©charger la vid√©o si disponible
                if scene.video_url:
                    scene.local_path = await self.download_video(scene.video_url, scene_num)
                else:
                    print(f"‚ö†Ô∏è Pas de vid√©o g√©n√©r√©e pour sc√®ne {scene_num}")
                    # Cr√©er un fichier factice pour continuer
                    fake_path = self.cache_dir / f"scene_{scene_num}_missing.mp4"
                    fake_path.touch()
                    scene.local_path = str(fake_path)
                
                animation_scenes.append(scene)
                print(f"‚úÖ Sc√®ne {scene_num} trait√©e")
            
            # 7. Assembler l'animation finale
            print("üé¨ Assemblage de l'animation finale...")
            
            timestamp = int(time.time())
            output_filename = f"crewai_animation_{timestamp}.mp4"
            output_path = str(self.cache_dir / output_filename)
            
            final_animation_path = self.assemble_final_animation(animation_scenes, output_path, editing_result)
            
            # 8. Pr√©parer le r√©sultat complet
            total_time = time.time() - start_time
            
            result = {
                "status": "success",
                "video_path": final_animation_path,
                "video_url": f"/static/cache/crewai_animations/{output_filename}",
                "scenes_count": len(animation_scenes),
                "total_duration": sum(scene.duration for scene in animation_scenes),
                "generation_time": round(total_time, 2),
                "pipeline_type": "crewai_multi_agent",
                "agents_used": list(agents.keys()),
                "scenes_details": [
                    {
                        "scene_number": scene.scene_number,
                        "description": scene.description,
                        "duration": scene.duration,
                        "action": scene.action,
                        "setting": scene.setting,
                        "status": scene.status,
                        "prompt": scene.visual_prompt,
                        "seed": scene.seed
                    }
                    for scene in animation_scenes
                ],
                "visual_style": visual_style,
                "narrative_analysis": scenario_result.get("story_analysis", {}),
                "editing_plan": editing_result,
                "timestamp": datetime.now().isoformat(),
                "story_input": story_text,
                "style_preferences": style_preferences
            }
            
            print(f"üéâ === ANIMATION CREWAI G√âN√âR√âE AVEC SUCC√àS ===")
            print(f"‚è±Ô∏è  Temps total: {total_time:.1f}s")
            print(f"üé¨ Vid√©o: {final_animation_path}")
            print(f"üìä {len(animation_scenes)} sc√®nes assembl√©es")
            print(f"üë• {len(agents)} agents utilis√©s")
            
            return result
            
        except Exception as e:
            print(f"‚ùå Erreur g√©n√©ration CrewAI: {e}")
            import traceback
            traceback.print_exc()
            
            return {
                "status": "error",
                "error": str(e),
                "timestamp": datetime.now().isoformat(),
                "generation_time": time.time() - start_time,
                "pipeline_type": "crewai_multi_agent"
            }
    
    def _parse_json_result(self, result_text: str) -> Dict[str, Any]:
        """Parser le r√©sultat JSON d'un agent avec gestion d'erreur"""
        try:
            # Nettoyer le texte et extraire le JSON
            if "```json" in result_text:
                json_start = result_text.find("```json") + 7
                json_end = result_text.find("```", json_start)
                if json_end != -1:
                    result_text = result_text[json_start:json_end]
            
            return json.loads(result_text)
        except Exception as e:
            print(f"‚ö†Ô∏è Erreur parsing JSON: {e}")
            return {}

# Instance globale
animation_crewai_service = AnimationCrewAIService()
