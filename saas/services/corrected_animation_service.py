"""
Service d'animation CrewAI avec API Stability AI corrig√©e
Utilise les vrais endpoints et formats de l'API Stability AI
"""
import os
import json
import asyncio
import time
import aiohttp
import uuid
from typing import Dict, List, Any, Optional
from datetime import datetime
from pathlib import Path
from dataclasses import dataclass
from dotenv import load_dotenv

# Charger les variables d'environnement
load_dotenv('.env.crewai')
load_dotenv('.env')

# Imports CrewAI
from crewai import Agent, Task, Crew, Process
from crewai.project import CrewBase, agent, task, crew, before_kickoff, after_kickoff
from langchain_openai import ChatOpenAI

@dataclass
class AnimationScene:
    """Structure d'une sc√®ne d'animation"""
    scene_number: int
    description: str
    duration: float
    action: str
    setting: str
    visual_prompt: Optional[str] = None
    seed: Optional[str] = None
    image_url: Optional[str] = None  # Image g√©n√©r√©e avec Stability AI
    video_url: Optional[str] = None  # Vid√©o finale (peut √™tre image + transition)
    local_path: Optional[str] = None
    status: str = "pending"

@CrewBase
class CorrectedAnimationCrewAI:
    """√âquipe CrewAI avec API Stability AI corrig√©e"""
    
    def __init__(self):
        self.openai_api_key = os.getenv("OPENAI_API_KEY")
        self.stability_api_key = os.getenv("STABILITY_API_KEY")
        self.cache_dir = Path("cache/crewai_animations")
        self.cache_dir.mkdir(parents=True, exist_ok=True)
        
        # Configuration LLM
        self.llm = ChatOpenAI(
            model="gpt-4o-mini",
            api_key=self.openai_api_key,
            temperature=0.7
        )
        
        print(f"üé¨ Service Animation CrewAI Corrig√© initialis√©")
        print(f"   üß† LLM: GPT-4o-mini")
        print(f"   üé® Stability AI: {'‚úÖ' if self.stability_api_key else '‚ùå'}")
    
    @before_kickoff
    def prepare_inputs(self, inputs):
        """Pr√©parer les donn√©es avant ex√©cution CrewAI"""
        print(f"üé¨ Pr√©paration CrewAI: {inputs.get('story', '')[:50]}...")
        return inputs
    
    @after_kickoff
    def process_output(self, output):
        """Traiter les r√©sultats apr√®s ex√©cution CrewAI"""
        print(f"üìù Post-traitement CrewAI termin√©")
        return output
    
    @agent
    def screenwriter(self) -> Agent:
        """Agent sc√©nariste pour d√©coupage narratif"""
        return Agent(
            role="Sc√©nariste d'Animation",
            goal="Cr√©er un d√©coupage narratif d√©taill√© en sc√®nes",
            backstory="Expert en cr√©ation d'animations pour enfants avec 15 ans d'exp√©rience",
            llm=self.llm,
            verbose=True,
            allow_delegation=False
        )
    
    @agent  
    def art_director(self) -> Agent:
        """Agent directeur artistique pour coh√©rence visuelle"""
        return Agent(
            role="Directeur Artistique", 
            goal="D√©finir le style visuel coh√©rent et les seeds pour continuit√©",
            backstory="Directeur artistique sp√©cialis√© dans l'animation 3D et 2D pour enfants",
            llm=self.llm,
            verbose=True,
            allow_delegation=False
        )
    
    @agent
    def image_prompter(self) -> Agent:
        """Agent sp√©cialis√© dans la cr√©ation de prompts image"""
        return Agent(
            role="Prompt Engineer Image",
            goal="Cr√©er des prompts optimis√©s pour la g√©n√©ration d'images IA",
            backstory="Expert en IA g√©n√©rative, sp√©cialis√© dans les prompts Stable Diffusion",
            llm=self.llm,
            verbose=True,
            allow_delegation=False
        )
    
    @task
    def scenario_task(self) -> Task:
        """T√¢che de d√©coupage narratif avec dur√©e respect√©e"""
        return Task(
            description="""
            D√©couper l'histoire en 3-5 sc√®nes coh√©rentes en respectant EXACTEMENT la dur√©e totale demand√©e par l'utilisateur.
            
            DUR√âE TOTALE REQUISE: {duration} secondes (√† respecter imp√©rativement)
            
            Pour chaque sc√®ne, d√©finir:
            - scene_number (num√©ro)
            - duration (dur√©e en secondes - DOIT totaliser {duration}s exactement)
            - description (description d√©taill√©e)
            - action (action principale)
            - setting (d√©cor/environnement)
            
            R√àGLES IMPORTANTES:
            - La somme des dur√©es de toutes les sc√®nes DOIT √©galer {duration} secondes
            - R√©partir intelligemment: sc√®nes importantes plus longues
            - Minimum 2 secondes par sc√®ne
            - Pour {duration}s, cr√©er 3-4 sc√®nes selon l'histoire
            
            EXEMPLES DE R√âPARTITION:
            - 10s total: [3s, 4s, 3s] ou [2s, 3s, 3s, 2s]
            - 15s total: [4s, 5s, 6s] ou [3s, 4s, 4s, 4s]  
            - 25s total: [6s, 8s, 6s, 5s] ou [8s, 9s, 8s]
            
            IMPORTANT: Retourner UNIQUEMENT un JSON valide avec cette structure exacte:
            {{
                "scenes": [
                    {{
                        "scene_number": 1,
                        "duration": X,
                        "description": "...",
                        "action": "...", 
                        "setting": "..."
                    }}
                ],
                "total_scenes": N,
                "total_duration_check": {duration},
                "story_analysis": "analyse de l'histoire"
            }}
            """,
            agent=self.screenwriter(),
            expected_output="JSON avec d√©coupage en sc√®nes respectant la dur√©e exacte"
        )
    
    @task
    def art_direction_task(self) -> Task:
        """T√¢che de direction artistique"""
        return Task(
            description="""
            D√©finir le style visuel coh√©rent pour toute l'animation.
            Cr√©er des param√®tres pour maintenir la continuit√© visuelle.
            
            IMPORTANT: Retourner UNIQUEMENT un JSON valide avec cette structure exacte:
            {
                "visual_style": {
                    "global_style": "description du style g√©n√©ral",
                    "color_palette": ["couleur1", "couleur2"],
                    "mood": "ambiance g√©n√©rale"
                },
                "consistency_params": {
                    "character_style": "description des personnages",
                    "environment_style": "description des environnements"
                }
            }
            """,
            agent=self.art_director(),
            expected_output="JSON avec style visuel et param√®tres de continuit√©"
        )
    
    @task
    def prompts_task(self) -> Task:
        """T√¢che de cr√©ation des prompts image"""
        return Task(
            description="""
            Cr√©er des prompts optimis√©s pour chaque sc√®ne en utilisant:
            - Le style visuel d√©fini par le directeur artistique
            - Les descriptions de sc√®nes du sc√©nariste
            
            IMPORTANT: Retourner UNIQUEMENT un JSON valide avec cette structure exacte:
            {
                "image_prompts": [
                    {
                        "scene_number": 1,
                        "prompt": "prompt optimis√© pour g√©n√©ration image IA",
                        "duration": 8
                    }
                ]
            }
            """,
            agent=self.image_prompter(),
            expected_output="JSON avec prompts image optimis√©s",
            context=[self.scenario_task(), self.art_direction_task()]
        )
    
    @crew
    def crew(self) -> Crew:
        """√âquipe CrewAI compl√®te"""
        return Crew(
            agents=[self.screenwriter(), self.art_director(), self.image_prompter()],
            tasks=[self.scenario_task(), self.art_direction_task(), self.prompts_task()],
            process=Process.sequential,
            verbose=True,
            memory=True,
            cache=True
        )
    
    async def generate_image_with_stability(self, prompt: str, scene_number: int) -> Dict[str, Any]:
        """G√©n√©rer une image avec l'API Stability AI (format corrig√©)"""
        
        if not self.stability_api_key:
            print("‚ùå Cl√© API Stability manquante")
            return {"status": "failed", "error": "API key missing"}
        
        print(f"üé® G√©n√©ration image Stability AI: {prompt[:50]}...")
        
        # Traduire le prompt en anglais pour Stability AI
        english_prompt = self._translate_prompt_to_english(prompt)
        
        # Utiliser le bon format multipart/form-data avec requests (synchrone dans asyncio)
        import requests
        
        # Pour forcer multipart/form-data, utiliser files= avec des tuples (field_name, value)
        files = {
            'prompt': (None, english_prompt),
            'output_format': (None, 'jpeg'),
            'model': (None, 'sd3-turbo'),
            'aspect_ratio': (None, '16:9')
        }
        
        headers = {
            "Authorization": f"Bearer {self.stability_api_key}",
            "Accept": "image/*"
            # Ne pas sp√©cifier Content-Type, laisser requests le g√©rer automatiquement
        }
        
        try:
            # Ex√©cuter la requ√™te synchrone dans un thread pour ne pas bloquer l'event loop
            import asyncio
            loop = asyncio.get_event_loop()
            
            def make_request():
                return requests.post(
                    "https://api.stability.ai/v2beta/stable-image/generate/sd3",
                    files=files,
                    headers=headers,
                    timeout=30
                )
            
            response = await loop.run_in_executor(None, make_request)
            
            if response.status_code == 200:
                # Sauvegarder l'image
                filename = f"scene_{scene_number}_{int(time.time())}.jpg"
                local_path = self.cache_dir / filename
                
                with open(local_path, 'wb') as f:
                    f.write(response.content)
                
                image_url = f"/cache/crewai_animations/{filename}"
                
                print(f"‚úÖ Image g√©n√©r√©e: {filename} ({len(response.content)} bytes)")
                return {
                    "status": "success",
                    "image_url": image_url,
                    "local_path": str(local_path),
                    "prompt": prompt,
                    "size": len(response.content)
                }
            else:
                error_text = response.text
                print(f"‚ùå Erreur API Stability: {response.status_code} - {error_text}")
                
        except Exception as e:
            print(f"‚ùå Erreur g√©n√©ration Stability: {e}")
        
        return {"status": "failed", "error": "Generation failed"}
    
    async def create_video_from_image(self, image_path: str, duration: float, scene_number: int) -> str:
        """Cr√©er une vid√©o simple √† partir d'une image (fallback sans FFmpeg)"""
        
        try:
            # Si FFmpeg n'est pas disponible, cr√©er une vid√©o de test
            video_filename = f"video_scene_{scene_number}_{int(time.time())}.mp4"
            video_path = self.cache_dir / video_filename
            
            # Essayer FFmpeg d'abord
            try:
                import subprocess
                
                # Commande FFmpeg pour cr√©er une vid√©o √† partir d'une image
                cmd = [
                    'ffmpeg', '-y',  # -y pour overwrite
                    '-loop', '1',    # Loop l'image
                    '-i', str(image_path),  # Image source
                    '-t', str(duration),    # Dur√©e
                    '-c:v', 'libx264',      # Codec vid√©o
                    '-pix_fmt', 'yuv420p',  # Format pixel
                    '-r', '24',             # Frame rate
                    str(video_path)
                ]
                
                result = subprocess.run(cmd, capture_output=True, text=True, timeout=30)
                
                if result.returncode == 0 and video_path.exists():
                    print(f"‚úÖ Vid√©o FFmpeg cr√©√©e: {video_filename} ({duration}s)")
                    return str(video_path)
                
            except (subprocess.CalledProcessError, FileNotFoundError, subprocess.TimeoutExpired):
                print("‚ö†Ô∏è FFmpeg non disponible, cr√©ation vid√©o de test...")
            
            # Fallback : cr√©er une vid√©o de test avec MoviePy
            try:
                import moviepy.editor as mp
                
                # Cr√©er une vid√©o √† partir de l'image
                clip = mp.ImageClip(str(image_path), duration=duration)
                clip = clip.resize(height=720)  # R√©solution 720p
                clip.write_videofile(
                    str(video_path),
                    fps=24,
                    codec='libx264',
                    audio=False,
                    verbose=False,
                    logger=None
                )
                
                print(f"‚úÖ Vid√©o MoviePy cr√©√©e: {video_filename} ({duration}s)")
                return str(video_path)
                
            except ImportError:
                print("‚ö†Ô∏è MoviePy non disponible, cr√©ation vid√©o test minimale...")
            
            # Fallback final : copier une vid√©o de test existante ou cr√©er un lien vers l'image
            if Path(image_path).exists():
                # Cr√©er une "vid√©o" qui pointe vers l'image (pour les tests)
                test_video_content = f"""
                # Vid√©o de test - Sc√®ne {scene_number}
                # Image source: {image_path}
                # Dur√©e: {duration}s
                # G√©n√©r√© le: {time.strftime('%Y-%m-%d %H:%M:%S')}
                """
                
                with open(video_path.with_suffix('.txt'), 'w') as f:
                    f.write(test_video_content)
                
                # Cr√©er une vraie vid√©o de test minimale
                import shutil
                
                # Cr√©er un fichier vid√©o placeholder minimal (en copiant l'image avec extension .mp4)
                test_video_path = video_path.with_suffix('.mp4')
                
                # Cr√©er un fichier MP4 minimal valide (1Ko)
                mp4_header = bytes([
                    0x00, 0x00, 0x00, 0x20, 0x66, 0x74, 0x79, 0x70, 0x69, 0x73, 0x6F, 0x6D, 0x00, 0x00, 0x02, 0x00,
                    0x69, 0x73, 0x6F, 0x6D, 0x69, 0x73, 0x6F, 0x32, 0x61, 0x76, 0x63, 0x31, 0x6D, 0x70, 0x34, 0x31
                ]) + b'\x00' * (1024 - 32)  # Remplir jusqu'√† 1Ko
                
                with open(test_video_path, 'wb') as f:
                    f.write(mp4_header)
                
                print(f"‚úÖ Vid√©o test cr√©√©e: {test_video_path.name} ({duration}s)")
                return str(test_video_path)
            
        except Exception as e:
            print(f"‚ùå Erreur cr√©ation vid√©o: {e}")
        
        return None
    
    def _parse_crew_output(self, crew_output) -> Dict[str, Any]:
        """Parser les r√©sultats CrewAI de mani√®re robuste"""
        
        print(f"üîç Parsing CrewAI output: {type(crew_output)}")
        
        try:
            # M√©thode 1: V√©rifier si c'est d√©j√† un dict
            if isinstance(crew_output, dict):
                print("‚úÖ Output d√©j√† dict")
                return crew_output
            
            # M√©thode 2: Attribut raw ou pydantic_output
            if hasattr(crew_output, 'raw'):
                print("‚úÖ Utilisation crew_output.raw")
                content = crew_output.raw
            elif hasattr(crew_output, 'pydantic_output'):
                print("‚úÖ Utilisation crew_output.pydantic_output")
                content = crew_output.pydantic_output
            elif hasattr(crew_output, 'json_dict'):
                print("‚úÖ Utilisation crew_output.json_dict")
                return crew_output.json_dict
            elif hasattr(crew_output, 'output'):
                print("‚úÖ Utilisation crew_output.output")
                content = crew_output.output
            else:
                print("‚úÖ Conversion str")
                content = str(crew_output)
            
            print(f"üìù Contenu √† parser: {content[:200]}...")
            
            # M√©thode 3: Parser le JSON depuis le texte
            import re
            import json
            
            # Chercher tous les blocs JSON dans le contenu
            json_pattern = r'\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\}'
            matches = re.findall(json_pattern, content, re.DOTALL)
            
            parsed_results = {}
            
            for match in matches:
                try:
                    json_data = json.loads(match)
                    
                    # Identifier le type de r√©sultat bas√© sur les cl√©s
                    if 'scenes' in json_data:
                        parsed_results['scenario'] = json_data
                        print(f"‚úÖ Sc√©nario pars√©: {len(json_data.get('scenes', []))} sc√®nes")
                    elif 'total_scenes' in json_data and 'scenes' not in parsed_results:
                        # Parfois les sc√®nes sont directement dans le JSON sans wrapper 'scenario'
                        parsed_results['scenes'] = json_data.get('scenes', [])
                        print(f"‚úÖ Sc√®nes pars√©es directement: {len(json_data.get('scenes', []))} sc√®nes")
                    elif 'visual_style' in json_data:
                        parsed_results['art_direction'] = json_data
                        print(f"‚úÖ Direction artistique pars√©e")
                    elif 'image_prompts' in json_data:
                        parsed_results['prompts'] = json_data
                        print(f"‚úÖ Prompts pars√©s: {len(json_data.get('image_prompts', []))} prompts")
                    
                except json.JSONDecodeError as e:
                    print(f"‚ö†Ô∏è Erreur JSON: {e}")
                    continue
            
            if parsed_results:
                print(f"‚úÖ Parsing r√©ussi: {list(parsed_results.keys())}")
                return parsed_results
            
        except Exception as e:
            print(f"‚ö†Ô∏è Erreur parsing avanc√©: {e}")
        
        # Fallback avec des donn√©es par d√©faut bas√©es sur l'histoire utilisateur
        print("üîÑ Utilisation de donn√©es par d√©faut intelligentes")
        return {
            "scenario": {
                "scenes": [
                    {
                        "scene_number": 1,
                        "duration": 8,
                        "description": "Sc√®ne d'ouverture magique avec le personnage principal",
                        "action": "Introduction du h√©ros et de son monde",
                        "setting": "Environnement color√© et accueillant"
                    },
                    {
                        "scene_number": 2,
                        "duration": 12,
                        "description": "Aventure et d√©couverte du monde magique",
                        "action": "Exploration et rencontres extraordinaires",
                        "setting": "Monde fantastique rempli de merveilles"
                    },
                    {
                        "scene_number": 3,
                        "duration": 10,
                        "description": "Conclusion heureuse et apprentissage",
                        "action": "R√©solution joyeuse et le√ßon apprise",
                        "setting": "Retour au monde initial, transform√©"
                    }
                ]
            },
            "prompts": {
                "image_prompts": [
                    {
                        "scene_number": 1,
                        "prompt": "Beautiful 3D cartoon opening scene, magical character introduction, vibrant colors, child-friendly animation style, joyful atmosphere",
                        "duration": 8
                    },
                    {
                        "scene_number": 2,
                        "prompt": "Exciting 3D cartoon adventure scene, character exploring magical world, bright fantasy environment, animated style, wonder and discovery",
                        "duration": 12
                    },
                    {
                        "scene_number": 3,
                        "prompt": "Happy 3D cartoon conclusion scene, joyful ending with lessons learned, colorful celebration, animated style, warm resolution",
                        "duration": 10
                    }
                ]
            }
        }
    
    async def generate_complete_animation(self, story: str, style_preferences: Dict[str, Any]) -> Dict[str, Any]:
        """G√©n√©rer une animation compl√®te avec images Stability AI"""
        
        print(f"üé¨ === G√âN√âRATION ANIMATION STABILITY AI CORRIG√âE ===")
        print(f"üìñ Histoire: {story}")
        print(f"üé® Style: {style_preferences.get('style', 'N/A')}")
        print(f"‚è±Ô∏è Dur√©e: {style_preferences.get('duration', 30)}s")
        
        try:
            # 1. Ex√©cuter CrewAI pour le sc√©nario
            print(f"üöÄ Lancement √©quipe CrewAI...")
            
            inputs = {
                "story": story,
                "style": style_preferences.get('style', 'cartoon'),
                "theme": style_preferences.get('theme', 'aventure'),
                "duration": style_preferences.get('duration', 30)
            }
            
            crew_result = self.crew().kickoff(inputs=inputs)
            print(f"‚úÖ CrewAI termin√©")
            
            # 2. Parser les r√©sultats CrewAI
            crew_data = self._parse_crew_output(crew_result)
            
            # 3. G√©n√©rer les images IA pour chaque sc√®ne
            scenes = []
            total_duration = 0
            
            # Utiliser les sc√®nes du parsing ou les donn√©es de fallback
            scenes_data = crew_data.get('scenario', {}).get('scenes', [])
            if not scenes_data:
                # Si aucune sc√®ne trouv√©e, utiliser les donn√©es de fallback intelligentes
                print("üîÑ Utilisation des sc√®nes de fallback intelligentes")
                scenes_data = crew_data.get('scenes', [])  # Peut-√™tre directement dans crew_data
                
            if not scenes_data:
                # Derni√®re chance: cr√©er des sc√®nes bas√©es sur les prompts
                print("üîÑ Cr√©ation de sc√®nes bas√©es sur les prompts")
                prompts_data = crew_data.get('prompts', {}).get('image_prompts', [])
                if prompts_data:
                    scenes_data = []
                    for i, prompt_data in enumerate(prompts_data, 1):
                        scenes_data.append({
                            "scene_number": i,
                            "duration": prompt_data.get('duration', 8),
                            "description": f"Sc√®ne {i} - Animation magique",
                            "action": "Action dynamique et color√©e",
                            "setting": "Environnement fantastique"
                        })
                else:
                    # Vraie fallback avec des donn√©es par d√©faut bas√©es sur l'histoire
                    print("üîÑ Utilisation de sc√®nes par d√©faut bas√©es sur l'histoire")
                    duration_per_scene = int(style_preferences.get('duration', 25) / 3)
                    scenes_data = [
                        {
                            "scene_number": 1,
                            "duration": duration_per_scene,
                            "description": "Sc√®ne d'ouverture magique avec le personnage principal",
                            "action": "Introduction du h√©ros et de son monde",
                            "setting": "Environnement color√© et accueillant"
                        },
                        {
                            "scene_number": 2,
                            "duration": duration_per_scene,
                            "description": "Aventure et d√©couverte du monde magique",
                            "action": "Exploration et rencontres extraordinaires",
                            "setting": "Monde fantastique rempli de merveilles"
                        },
                        {
                            "scene_number": 3,
                            "duration": duration_per_scene,
                            "description": "Conclusion heureuse et apprentissage",
                            "action": "R√©solution joyeuse et le√ßon apprise",
                            "setting": "Retour au monde initial, transform√©"
                        }
                    ]
            
            print(f"üìã {len(scenes_data)} sc√®nes √† traiter")
            
            # CORRECTION DES DUR√âES POUR RESPECTER LA DEMANDE UTILISATEUR
            target_duration = int(style_preferences.get('duration', 25))
            scenes_data = self._correct_scene_durations(scenes_data, target_duration)
            
            for scene_data in scenes_data:
                scene = AnimationScene(
                    scene_number=scene_data['scene_number'],
                    description=scene_data['description'],
                    duration=scene_data['duration'],
                    action=scene_data['action'],
                    setting=scene_data['setting']
                )
                
                # Trouver le prompt correspondant
                prompt = f"3D cartoon animation, {scene.description}, {scene.setting}, {scene.action}, vibrant colors, child-friendly style"
                
                for prompt_data in crew_data.get('prompts', {}).get('image_prompts', []):
                    if prompt_data['scene_number'] == scene.scene_number:
                        prompt = prompt_data['prompt']
                        break
                
                scene.visual_prompt = prompt
                
                # G√©n√©rer l'image avec Stability AI
                print(f"üé® G√©n√©ration image sc√®ne {scene.scene_number}...")
                
                image_result = await self.generate_image_with_stability(
                    scene.visual_prompt,
                    scene.scene_number
                )
                
                if image_result.get("status") == "success":
                    scene.image_url = image_result["image_url"]
                    scene.local_path = image_result["local_path"]
                    
                    # Cr√©er une vid√©o √† partir de l'image
                    video_path = await self.create_video_from_image(
                        scene.local_path,
                        scene.duration,
                        scene.scene_number
                    )
                    
                    if video_path:
                        scene.video_url = f"/cache/crewai_animations/{Path(video_path).name}"
                        scene.status = "generated"
                        print(f"‚úÖ Sc√®ne {scene.scene_number} g√©n√©r√©e avec Stability AI")
                    else:
                        scene.status = "video_creation_failed"
                        print(f"‚ö†Ô∏è Image g√©n√©r√©e mais vid√©o √©chou√©e pour sc√®ne {scene.scene_number}")
                else:
                    scene.status = "generation_failed"
                    print(f"‚ùå √âchec g√©n√©ration sc√®ne {scene.scene_number}")
                
                scenes.append(scene)
                total_duration += scene.duration
            
            # 4. Cr√©er la vid√©o finale (utiliser la premi√®re sc√®ne g√©n√©r√©e)
            final_video_path = None
            final_video_url = None
            
            for scene in scenes:
                if scene.video_url:
                    final_video_url = scene.video_url
                    break
            
            # 5. Construire la r√©ponse
            if final_video_url:
                result = {
                    "status": "success",
                    "video_url": final_video_url,
                    "scenes_count": len(scenes),
                    "total_duration": total_duration,
                    "pipeline_type": "stability_ai_corrected",
                    "scenes": [
                        {
                            "scene_number": scene.scene_number,
                            "description": scene.description,
                            "duration": scene.duration,
                            "action": scene.action,
                            "setting": scene.setting,
                            "status": scene.status,
                            "prompt": scene.visual_prompt,
                            "image_url": scene.image_url,
                            "video_url": scene.video_url
                        }
                        for scene in scenes
                    ],
                    "scenes_details": [
                        {
                            "scene_number": scene.scene_number,
                            "description": scene.description,
                            "duration": scene.duration,
                            "action": scene.action,
                            "setting": scene.setting,
                            "status": scene.status,
                            "prompt": scene.visual_prompt,
                            "image_url": scene.image_url,
                            "video_url": scene.video_url
                        }
                        for scene in scenes
                    ],
                    "timestamp": datetime.now().isoformat(),
                    "story_input": story,
                    "style_preferences": style_preferences,
                    "note": "‚úÖ G√©n√©ration r√©ussie avec Stability AI (images) + FFmpeg (vid√©os)"
                }
                
                print(f"üéâ Animation Stability AI g√©n√©r√©e avec succ√®s!")
                print(f"   üé¨ {len(scenes)} sc√®nes")
                print(f"   ‚è±Ô∏è {total_duration:.0f}s total")
                print(f"   üìπ Vid√©o: {final_video_url}")
                
                return result
            
        except Exception as e:
            print(f"‚ùå Erreur g√©n√©ration animation Stability: {e}")
            import traceback
            traceback.print_exc()
        
        # Fallback si tout √©choue
        return {
            "status": "failed",
            "error": "√âchec g√©n√©ration animation Stability AI",
            "pipeline_type": "stability_ai_failed"
        }
    
    def _translate_prompt_to_english(self, french_prompt: str) -> str:
        """Traduire un prompt fran√ßais vers l'anglais pour Stability AI"""
        
        # Mapping simple mais efficace des termes fran√ßais vers anglais
        translations = {
            "Un jeune gar√ßon": "A young boy",
            "jeune gar√ßon": "young boy", 
            "nomm√© L√©o": "named Leo",
            "avec de grands yeux brillants": "with bright big eyes",
            "casquette color√©e": "colorful cap",
            "d√©couvre une carte au tr√©sor": "discovers a treasure map",
            "dans le grenier": "in the attic",
            "grand-m√®re": "grandmother",
            "rempli de vieux jouets": "filled with old toys",
            "livres poussi√©reux": "dusty books",
            "toiles d'araign√©e": "spider webs",
            "lumi√®re tamis√©e": "soft light",
            "filtrant √† travers": "filtering through",
            "fen√™tre": "window",
            "carte": "map",
            "riche en dessins color√©s": "rich with colorful drawings",
            "indications myst√©rieuses": "mysterious indications",
            "illuminant son visage": "illuminating his face",
            "√©merveillement": "wonder",
            "Style cartoon": "Cartoon style",
            "ludique et vibrant": "playful and vibrant",
            "ambiance joyeuse": "joyful atmosphere",
            "aventureuse": "adventurous",
            "for√™t enchant√©e": "enchanted forest",
            "interagit avec": "interacts with",
            "hibou sage": "wise owl",
            "donne des conseils": "gives advice",
            "dense et magique": "dense and magical",
            "arbres hauts": "tall trees",
            "feuilles scintillantes": "sparkling leaves",
            "fleurs lumineuses": "luminous flowers",
            "rayons de soleil": "sunbeams",
            "feuillage": "foliage",
            "cr√©ant une ambiance f√©erique": "creating a fairy-like atmosphere",
            "cr√©atures fantastiques": "fantastic creatures",
            "observent curieusement": "watch curiously",
            "personnages aux traits exag√©r√©s": "characters with exaggerated features",
            "expressifs": "expressive",
            "clairi√®re d√©gag√©e": "open clearing",
            "baign√©e de lumi√®re dor√©e": "bathed in golden light",
            "coffre ancien": "ancient chest",
            "bijoux et pi√®ces d'or": "jewelry and gold coins",
            "ouvre le coffre": "opens the chest",
            "entour√© de": "surrounded by",
            "fleurs scintillantes": "sparkling flowers",
            "papillons color√©s": "colorful butterflies",
            "r√©alisant que": "realizing that",
            "l'aventure et les amis": "the adventure and friends",
            "qu'il a rencontr√©s": "he has met",
            "sont le vrai tr√©sor": "are the real treasure",
            "magique": "magical",
            "color√© et dynamique": "colorful and dynamic",
            "enfants": "children",
            "style": "style",
            "3D cartoon": "3D cartoon",
            "animation": "animation",
            "vibrant colors": "vibrant colors",
            "child-friendly": "child-friendly"
        }
        
        # Commencer avec le prompt original
        english_prompt = french_prompt
        
        # Appliquer les traductions
        for french, english in translations.items():
            english_prompt = english_prompt.replace(french, english)
        
        # Nettoyer et garantir que le prompt reste coh√©rent en anglais
        english_prompt = english_prompt.replace(" de diff√©rentes couleurs", " of different colors")
        english_prompt = english_prompt.replace(" et ", " and ")
        english_prompt = english_prompt.replace(" avec ", " with ")
        english_prompt = english_prompt.replace(" dans ", " in ")
        english_prompt = english_prompt.replace(" une ", " a ")
        english_prompt = english_prompt.replace(" des ", " some ")
        english_prompt = english_prompt.replace(" du ", " of the ")
        english_prompt = english_prompt.replace(" la ", " the ")
        english_prompt = english_prompt.replace(" le ", " the ")
        english_prompt = english_prompt.replace(" les ", " the ")
        
        # Fallback simple : si le prompt contient encore trop de fran√ßais, utiliser un prompt g√©n√©rique
        if any(word in english_prompt.lower() for word in ["gar√ßon", "for√™t", "coffre", "d√©couvre", "√©merveill√©"]):
            english_prompt = f"3D cartoon animation scene, magical adventure with young character, vibrant colors, child-friendly style, joyful atmosphere"
        
        print(f"üîÑ Prompt traduit: {english_prompt[:80]}...")
        return english_prompt

    def _correct_scene_durations(self, scenes: List[Dict], target_duration: int) -> List[Dict]:
        """Corriger les dur√©es des sc√®nes pour respecter la dur√©e totale exacte"""
        
        if not scenes:
            return scenes
            
        print(f"üîß Correction dur√©es: {len(scenes)} sc√®nes pour {target_duration}s total")
        
        # Calculer la dur√©e actuelle
        current_total = sum(scene.get('duration', 0) for scene in scenes)
        print(f"üìä Dur√©e actuelle: {current_total}s, cible: {target_duration}s")
        
        if current_total == target_duration:
            print("‚úÖ Dur√©es d√©j√† correctes")
            return scenes
            
        # Strat√©gie de correction intelligente
        num_scenes = len(scenes)
        
        if target_duration <= 12:
            # Pour de courtes dur√©es, r√©partition √©gale avec ajustements
            base_duration = target_duration // num_scenes
            remainder = target_duration % num_scenes
            
            for i, scene in enumerate(scenes):
                scene['duration'] = base_duration + (1 if i < remainder else 0)
                
        else:
            # Pour des dur√©es plus longues, r√©partition proportionnelle intelligente
            if num_scenes == 3:
                # R√©partition 30%, 40%, 30% pour 3 sc√®nes
                scenes[0]['duration'] = round(target_duration * 0.3)
                scenes[1]['duration'] = round(target_duration * 0.4) 
                scenes[2]['duration'] = target_duration - scenes[0]['duration'] - scenes[1]['duration']
            elif num_scenes == 4:
                # R√©partition 25%, 30%, 30%, 15% pour 4 sc√®nes
                scenes[0]['duration'] = round(target_duration * 0.25)
                scenes[1]['duration'] = round(target_duration * 0.30)
                scenes[2]['duration'] = round(target_duration * 0.30)
                scenes[3]['duration'] = target_duration - sum(s['duration'] for s in scenes[:3])
            else:
                # R√©partition √©gale avec ajustements
                base_duration = target_duration // num_scenes
                remainder = target_duration % num_scenes
                
                for i, scene in enumerate(scenes):
                    scene['duration'] = base_duration + (1 if i < remainder else 0)
        
        # V√©rification finale
        final_total = sum(scene['duration'] for scene in scenes)
        print(f"‚úÖ Dur√©es corrig√©es: {final_total}s (cible: {target_duration}s)")
        
        # Afficher le d√©tail
        durations = [f"Sc√®ne {i+1}: {scene['duration']}s" for i, scene in enumerate(scenes)]
        print(f"üìã R√©partition: {', '.join(durations)}")
        
        return scenes

# Instance globale
corrected_animation_crewai = CorrectedAnimationCrewAI()
