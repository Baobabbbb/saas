"""
Service de gÃ©nÃ©ration de coloriages avec Stable Diffusion 3 + ControlNet
Transforme n'importe quelle photo en page de coloriage noir et blanc
"""
import os
import uuid
import base64
import cv2
import numpy as np
from datetime import datetime
from pathlib import Path
from typing import Dict, Any, Optional, Literal
from PIL import Image, ImageEnhance, ImageOps
import io
import requests
from dotenv import load_dotenv
from services.supabase_storage import get_storage_service

load_dotenv()


class ColoringGeneratorSD3ControlNet:
    """
    GÃ©nÃ©rateur de coloriages avec Stable Diffusion 3 et ControlNet
    Supporte Canny (dÃ©tection contours) et Scribble (style croquis)
    """
    
    def __init__(self):
        self.output_dir = Path("static/coloring")
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        self.upload_dir = Path("static/uploads/coloring")
        self.upload_dir.mkdir(parents=True, exist_ok=True)
        
        self.stability_key = os.getenv("STABILITY_API_KEY")
        
        # VÃ©rification de la clÃ© API
        if not self.stability_key:
            print("âŒ ERREUR: STABILITY_API_KEY non trouvÃ©e dans .env")
            raise ValueError("STABILITY_API_KEY manquante")
        
        print(f"âœ… ClÃ© Stability AI dÃ©tectÃ©e: {self.stability_key[:15]}...")
        
        # Configuration Stable Diffusion 3
        # Note: Utilisation de l'endpoint control/structure (ControlNet officiel)
        self.sd3_api_url = "https://api.stability.ai/v2beta/stable-image/control/structure"
        self.sd3_model = "sd3-medium"  # ou sd3-large
        
        # URL de base pour les images (production Railway ou local)
        self.base_url = os.getenv("BASE_URL", "https://herbbie.com")
        
        # Prompts optimisÃ©s pour coloriages
        self.base_prompt = """Convert this image into a black-and-white coloring book page. 
Clean outlines, simple cartoon-like drawing style, no shading, no gray areas, 
only black ink contours on white background. Suitable for kids to color. 
Keep the main subject recognizable and remove unnecessary background details."""
        
        self.negative_prompt = """no colors, no shading, no grey, no background clutter, 
no text, no logos, no watermarks, no realistic textures, no gradients, no shadows"""
        
        print(f"âœ… ColoringGeneratorSD3ControlNet initialisÃ©")
        print(f"   - ModÃ¨le: {self.sd3_model}")
        print(f"   - API: Stability AI Control Sketch")
    
    async def generate_coloring_from_photo(
        self, 
        photo_path: str,
        control_mode: Literal["canny", "scribble"] = "canny",
        control_strength: float = 0.7,
        custom_prompt: Optional[str] = None,
        user_id: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        Convertit une photo en coloriage avec ControlNet
        
        Args:
            photo_path: Chemin vers la photo
            control_mode: "canny" (contours nets) ou "scribble" (style croquis)
            control_strength: Force du contrÃ´le (0.5-1.0)
            custom_prompt: Prompt personnalisÃ© optionnel
        
        Returns:
            Dict avec le rÃ©sultat
        """
        try:
            print(f"ðŸŽ¨ Conversion photo en coloriage: {photo_path}")
            print(f"   - Mode ControlNet: {control_mode}")
            print(f"   - Force: {control_strength}")
            
            # 1. Charger et prÃ©parer la photo
            image = Image.open(photo_path)
            image = self._resize_image(image, max_size=1024)
            
            # 2. Appliquer ControlNet pour extraire les contours
            control_image = self._apply_controlnet(image, mode=control_mode)
            
            # 3. Sauvegarder l'image de contrÃ´le (debug)
            control_path = self.output_dir / f"control_{uuid.uuid4().hex[:8]}.png"
            control_image.save(control_path)
            print(f"âœ… Image de contrÃ´le sauvegardÃ©e: {control_path.name}")
            
            # 4. GÃ©nÃ©rer le coloriage avec SD3
            coloring_path = await self._generate_with_sd3_control(
                control_image=control_image,
                prompt=custom_prompt or self.base_prompt,
                control_strength=control_strength
            )
            
            if not coloring_path:
                raise Exception("Ã‰chec de la gÃ©nÃ©ration SD3")
            
            # 5. Post-traiter pour optimiser (noir/blanc pur)
            final_path = await self._post_process_coloring(coloring_path)
            
            # ðŸ“¤ Upload vers Supabase Storage si user_id fourni
            storage_service = get_storage_service()
            if storage_service and user_id:
                upload_result = await storage_service.upload_file(
                    file_path=str(final_path),
                    user_id=user_id,
                    content_type="coloring",
                    custom_filename=final_path.name
                )
                
                if upload_result["success"]:
                    image_url = upload_result["signed_url"]
                    control_image_url = image_url  # MÃªme fichier pour les deux
                    print(f"âœ… Image uploadÃ©e vers Supabase Storage")
                else:
                    image_url = f"{self.base_url}/static/coloring/{final_path.name}"
                    control_image_url = f"{self.base_url}/static/coloring/{control_path.name}"
                    print(f"âš ï¸ Upload Supabase Ã©chouÃ©, utilisation chemin local")
            else:
                image_url = f"{self.base_url}/static/coloring/{final_path.name}"
                control_image_url = f"{self.base_url}/static/coloring/{control_path.name}"
            
            # 6. Construire la rÃ©ponse
            result = {
                "success": True,
                "source_photo": photo_path,
                "images": [{
                    "image_url": image_url,
                    "control_mode": control_mode,
                    "control_strength": control_strength,
                    "source": "sd3_controlnet"
                }],
                "control_image_url": control_image_url,
                "total_images": 1,
                "metadata": {
                    "source_photo": photo_path,
                    "control_mode": control_mode,
                    "control_strength": control_strength,
                    "created_at": datetime.now().isoformat(),
                    "model": "sd3-controlnet"
                }
            }
            
            print(f"âœ… Coloriage gÃ©nÃ©rÃ© avec succÃ¨s: {final_path.name}")
            return result
            
        except Exception as e:
            print(f"âŒ Erreur conversion photo: {e}")
            import traceback
            traceback.print_exc()
            return {
                "success": False,
                "error": str(e),
                "images": []
            }
    
    def _resize_image(self, image: Image.Image, max_size: int = 1024) -> Image.Image:
        """Redimensionner l'image tout en gardant le ratio"""
        width, height = image.size
        
        if width > max_size or height > max_size:
            if width > height:
                new_width = max_size
                new_height = int(height * (max_size / width))
            else:
                new_height = max_size
                new_width = int(width * (max_size / height))
            
            image = image.resize((new_width, new_height), Image.Resampling.LANCZOS)
            print(f"ðŸ“ Image redimensionnÃ©e: {width}x{height} â†’ {new_width}x{new_height}")
        
        return image
    
    def _apply_controlnet(
        self, 
        image: Image.Image, 
        mode: Literal["canny", "scribble"]
    ) -> Image.Image:
        """
        Applique ControlNet pour extraire les contours
        
        Args:
            image: Image PIL
            mode: "canny" ou "scribble"
        
        Returns:
            Image PIL avec contours extraits
        """
        print(f"ðŸ” Application ControlNet ({mode})...")
        
        # Convertir PIL en numpy array
        img_array = np.array(image)
        
        # Convertir en niveaux de gris si nÃ©cessaire
        if len(img_array.shape) == 3:
            gray = cv2.cvtColor(img_array, cv2.COLOR_RGB2GRAY)
        else:
            gray = img_array
        
        if mode == "canny":
            # Canny Edge Detection - contours nets
            edges = self._apply_canny(gray)
        else:  # scribble
            # Scribble - style croquis simplifiÃ©
            edges = self._apply_scribble(gray)
        
        # Convertir en RGB pour compatibilitÃ©
        edges_rgb = cv2.cvtColor(edges, cv2.COLOR_GRAY2RGB)
        
        # Retourner en PIL Image
        control_image = Image.fromarray(edges_rgb)
        
        print(f"âœ… ControlNet appliquÃ© ({mode})")
        return control_image
    
    def _apply_canny(self, gray_image: np.ndarray) -> np.ndarray:
        """
        Applique Canny Edge Detection
        Produit des contours nets et prÃ©cis
        """
        # Appliquer un flou pour rÃ©duire le bruit
        blurred = cv2.GaussianBlur(gray_image, (5, 5), 1.4)
        
        # DÃ©tection de contours Canny
        # Seuils ajustables pour plus ou moins de dÃ©tails
        low_threshold = 50
        high_threshold = 150
        edges = cv2.Canny(blurred, low_threshold, high_threshold)
        
        # Dilater lÃ©gÃ¨rement les contours pour les rendre plus visibles
        kernel = np.ones((2, 2), np.uint8)
        edges = cv2.dilate(edges, kernel, iterations=1)
        
        # Inverser (fond blanc, contours noirs)
        edges = cv2.bitwise_not(edges)
        
        return edges
    
    def _apply_scribble(self, gray_image: np.ndarray) -> np.ndarray:
        """
        Applique un effet scribble/sketch
        Produit un style de croquis simplifiÃ©
        """
        # MÃ©thode 1: XDoG (eXtended Difference of Gaussians)
        sigma1 = 0.5
        sigma2 = 2.0
        
        # Appliquer deux flous gaussiens diffÃ©rents
        blur1 = cv2.GaussianBlur(gray_image, (0, 0), sigma1)
        blur2 = cv2.GaussianBlur(gray_image, (0, 0), sigma2)
        
        # DiffÃ©rence entre les deux
        dog = blur1 - blur2
        
        # Normaliser et seuiller
        dog = cv2.normalize(dog, None, 0, 255, cv2.NORM_MINMAX)
        _, edges = cv2.threshold(dog, 10, 255, cv2.THRESH_BINARY)
        
        # Inverser pour fond blanc
        edges = cv2.bitwise_not(edges)
        
        return edges
    
    async def _generate_with_sd3_control(
        self,
        control_image: Image.Image,
        prompt: str,
        control_strength: float
    ) -> Optional[Path]:
        """
        GÃ©nÃ¨re le coloriage avec Stable Diffusion 3 + Control Sketch
        
        Args:
            control_image: Image de contrÃ´le (contours)
            prompt: Prompt de gÃ©nÃ©ration
            control_strength: Force du contrÃ´le (0.5-1.0)
        
        Returns:
            Path vers l'image gÃ©nÃ©rÃ©e
        """
        try:
            print(f"ðŸŽ¨ GÃ©nÃ©ration SD3 avec Control Sketch...")
            print(f"   - Prompt: {prompt[:80]}...")
            
            # Convertir l'image de contrÃ´le en bytes
            img_byte_arr = io.BytesIO()
            control_image.save(img_byte_arr, format='PNG')
            img_byte_arr.seek(0)
            
            # PrÃ©parer la requÃªte
            headers = {
                "Authorization": f"Bearer {self.stability_key}",
                "Accept": "image/*"
            }
            
            files = {
                "image": ("control.png", img_byte_arr, "image/png")
            }
            
            data = {
                "prompt": prompt,
                "negative_prompt": self.negative_prompt,
                "control_strength": control_strength,
                "output_format": "png"
            }
            
            # Appeler l'API Stability AI silencieusement
            
            response = requests.post(
                self.sd3_api_url,
                headers=headers,
                files=files,
                data=data,
                timeout=60
            )
            
            print(f"ðŸ“¥ RÃ©ponse API: {response.status_code}")
            
            if response.status_code == 200:
                # Sauvegarder l'image gÃ©nÃ©rÃ©e
                output_path = self.output_dir / f"coloring_sd3_{uuid.uuid4().hex[:8]}.png"
                with open(output_path, 'wb') as f:
                    f.write(response.content)
                
                print(f"âœ… Image SD3 gÃ©nÃ©rÃ©e: {output_path.name}")
                return output_path
            else:
                error_msg = f"Erreur API Stability: {response.status_code}"
                try:
                    error_detail = response.json()
                    error_msg += f" - {error_detail}"
                except:
                    error_detail = response.text[:500]
                    error_msg += f" - {error_detail}"
                
                print(f"âŒ {error_msg}")
                raise Exception(error_msg)
                
        except Exception as e:
            print(f"âŒ Erreur gÃ©nÃ©ration SD3: {e}")
            import traceback
            traceback.print_exc()
            return None
    
    async def _post_process_coloring(self, image_path: Path) -> Path:
        """
        Post-traite l'image pour obtenir un coloriage optimal
        - Noir et blanc pur
        - Contours nets
        - Fond blanc
        """
        try:
            print(f"ðŸ”§ Post-traitement du coloriage...")
            
            with Image.open(image_path) as img:
                # Convertir en niveaux de gris
                gray = img.convert('L')
                
                # Augmenter le contraste pour des lignes plus nettes
                enhancer = ImageEnhance.Contrast(gray)
                high_contrast = enhancer.enhance(2.5)
                
                # Augmenter la luminositÃ© pour Ã©claircir le fond
                brightness_enhancer = ImageEnhance.Brightness(high_contrast)
                brightened = brightness_enhancer.enhance(1.2)
                
                # Appliquer un seuillage adaptatif pour noir/blanc pur
                # Plus le seuil est Ã©levÃ©, plus le fond sera blanc
                threshold = 200
                bw = brightened.point(lambda x: 0 if x < threshold else 255, '1')
                
                # Reconvertir en RGB
                final = bw.convert('RGB')
                
                # Nettoyer les petits artefacts (optionnel)
                # final = final.filter(ImageFilter.MedianFilter(size=3))
                
                # Sauvegarder
                final.save(image_path, 'PNG', optimize=True)
                
                print(f"âœ… Post-traitement terminÃ©")
                return image_path
                
        except Exception as e:
            print(f"âš ï¸ Erreur post-traitement: {e}")
            return image_path
    
    async def generate_coloring_from_theme(self, theme: str, user_id: Optional[str] = None) -> Dict[str, Any]:
        """
        GÃ©nÃ©ration par thÃ¨me (pour compatibilitÃ©)
        Note: Cette mÃ©thode n'utilise pas ControlNet car pas de photo source
        """
        print(f"âš ï¸ GÃ©nÃ©ration par thÃ¨me avec SD3 (sans ControlNet)")
        print(f"   Pour de meilleurs rÃ©sultats, utilisez generate_coloring_from_photo()")
        
        # Utiliser l'API SD3 standard pour gÃ©nÃ©ration de novo
        return await self._generate_theme_without_controlnet(theme)
    
    async def _generate_theme_without_controlnet(self, theme: str) -> Dict[str, Any]:
        """GÃ©nÃ©ration simple sans ControlNet (fallback)"""
        try:
            # CrÃ©er un prompt pour le thÃ¨me
            theme_prompts = {
                'animaux': "A cute cat in a meadow",
                'animals': "A friendly dog with a ball",
                'dinosaures': "A friendly T-Rex in a forest",
                'espace': "An astronaut floating in space",
                'fees': "A fairy with butterfly wings",
                'nature': "Sunflowers in a garden",
            }
            
            scene = theme_prompts.get(theme.lower(), f"A {theme} scene")
            
            prompt = f"{scene}. {self.base_prompt}"
            
            # Appeler SD3 sans ControlNet
            headers = {
                "Authorization": f"Bearer {self.stability_key}",
                "Accept": "image/*"
            }
            
            data = {
                "prompt": prompt,
                "negative_prompt": self.negative_prompt,
                "output_format": "png",
                "model": "sd3-medium"
            }
            
            response = requests.post(
                "https://api.stability.ai/v2beta/stable-image/generate/sd3",
                headers=headers,
                files={"none": ''},
                data=data,
                timeout=60
            )
            
            if response.status_code == 200:
                output_path = self.output_dir / f"coloring_{theme}_{uuid.uuid4().hex[:8]}.png"
                with open(output_path, 'wb') as f:
                    f.write(response.content)
                
                # Post-traiter
                final_path = await self._post_process_coloring(output_path)
                
                # ðŸ“¤ Upload vers Supabase Storage si user_id fourni
                storage_service = get_storage_service()
                if storage_service and user_id:
                    upload_result = await storage_service.upload_file(
                        file_path=str(final_path),
                        user_id=user_id,
                        content_type="coloring",
                        custom_filename=final_path.name
                    )
                    
                    if upload_result["success"]:
                        image_url = upload_result["signed_url"]
                        print(f"âœ… Image uploadÃ©e vers Supabase Storage")
                    else:
                        image_url = f"{self.base_url}/static/coloring/{final_path.name}"
                        print(f"âš ï¸ Upload Supabase Ã©chouÃ©, utilisation chemin local")
                else:
                    image_url = f"{self.base_url}/static/coloring/{final_path.name}"
                
                return {
                    "success": True,
                    "theme": theme,
                    "images": [{
                        "image_url": image_url,
                        "theme": theme,
                        "source": "sd3_standard"
                    }],
                    "total_images": 1,
                    "metadata": {
                        "theme": theme,
                        "created_at": datetime.now().isoformat(),
                        "model": "sd3-medium"
                    }
                }
            else:
                raise Exception(f"Erreur API: {response.status_code}")
                
        except Exception as e:
            print(f"âŒ Erreur gÃ©nÃ©ration thÃ¨me: {e}")
            return {
                "success": False,
                "error": str(e),
                "images": []
            }
    
    # MÃ©thodes de compatibilitÃ©
    async def generate_coloring_pages(self, theme: str) -> Dict[str, Any]:
        return await self.generate_coloring_from_theme(theme)
    
    async def generate_coloring(self, theme: str) -> Dict[str, Any]:
        return await self.generate_coloring_from_theme(theme)


# Instance globale
coloring_generator = ColoringGeneratorSD3ControlNet()

